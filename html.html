<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<!-- new favicon config and versions by realfavicongenerator.net -->
<link rel="apple-touch-icon" sizes="180x180" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon-16x16.png">
<link rel="manifest" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/site.webmanifest">
<link rel="mask-icon" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/safari-pinned-tab.svg" color="#b31b1b">
<link rel="shortcut icon" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon.ico">
<meta name="msapplication-TileColor" content="#b31b1b">
<meta name="msapplication-config" content="images/icons/browserconfig.xml">
<meta name="theme-color" content="#b31b1b">
<!-- end favicon config -->
<title>Search | arXiv e-print repository</title>
<script defer src="https://static.arxiv.org/static/base/1.0.0a5/fontawesome-free-5.11.2-web/js/all.js"></script>
<link rel="stylesheet" href="https://static.arxiv.org/static/base/1.0.0a5/css/arxivstyle.css" />
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    messageStyle: "none",
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true,
      ignoreClass: '.*',
      processClass: 'mathjax.*'
    },
    TeX: {
        extensions: ["AMSmath.js", "AMSsymbols.js", "noErrors.js"],
        noErrors: {
          inlineDelimiters: ["$","$"],
          multiLine: false,
          style: {
            "font-size": "normal",
            "border": ""
          }
        }
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>
<script src='//static.arxiv.org/MathJax-2.7.3/MathJax.js'></script>
<script src="https://static.arxiv.org/static/base/1.0.0a5/js/notification.js"></script>

    
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/bulma-tooltip.min.css" />
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/search.css" />
  <script
    src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
    integrity="sha256-k2WSCIexGzOj3Euiig+TlR8gA0EmPjuc79OEeY5L45g="
    crossorigin="anonymous"></script>

  <script src="https://static.arxiv.org/static/search/0.5.6/js/fieldset.js"></script>
  <style>
  radio#cf-customfield_11400 {
    display: none;
  }
  </style>

  </head>
  <body>
  
  
  <header><a href="#main-container" class="is-sr-only">Skip to main content</a>
    
    <!-- contains Cornell logo and sponsor statement -->
<div class="attribution level is-marginless" role="banner">
  <div class="level-left">
    <a class="level-item" href="https://cornell.edu/"><img src="https://static.arxiv.org/static/base/1.0.0a5/images/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" aria-label="logo" /></a>
  </div>
  <div class="level-right is-marginless"><p class="sponsors level-item is-marginless"><span id="support-ack-url">We gratefully acknowledge support from<br /> the Simons Foundation, <a href="https://info.arxiv.org/about/ourmembers.html">member institutions</a>, and all contributors. <a href="https://info.arxiv.org/about/donate.html">Donate</a></span></p></div>
</div>
<!-- contains arXiv identity and search bar -->
<div class="identity level is-marginless">
  <div class="level-left">
    <div class="level-item">
      <a class="arxiv" href="https://arxiv.org/" aria-label="arxiv-logo">
        <img src="https://static.arxiv.org/static/base/1.0.0a5/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;"/>
      </a>
    </div>
  </div>
  
  <div class="search-block level-right">
    <form class="level-item mini-search" method="GET" action="https://arxiv.org/search">
      <div class="field has-addons">
        <div class="control">
          <input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" />
          <p class="help"><a href="https://info.arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
        </div>
        <div class="control">
          <div class="select is-small">
            <select name="searchtype" aria-label="Field to search">
              <option value="all" selected="selected">All fields</option>
              <option value="title">Title</option>
              <option value="author">Author</option>
              <option value="abstract">Abstract</option>
              <option value="comments">Comments</option>
              <option value="journal_ref">Journal reference</option>
              <option value="acm_class">ACM classification</option>
              <option value="msc_class">MSC classification</option>
              <option value="report_num">Report number</option>
              <option value="paper_id">arXiv identifier</option>
              <option value="doi">DOI</option>
              <option value="orcid">ORCID</option>
              <option value="author_id">arXiv author ID</option>
              <option value="help">Help pages</option>
              <option value="full_text">Full text</option>
            </select>
          </div>
        </div>
        <input type="hidden" name="source" value="header">
        <button class="button is-small is-cul-darker">Search</button>
      </div>
    </form>
  </div>
</div> <!-- closes identity -->

<div class="container">
    <div class="user-tools is-size-7 has-text-right has-text-weight-bold" role="navigation" aria-label="User menu">
      <a href="https://arxiv.org/login">Login</a>
    </div>
</div>
    
  </header>
  <main class="container" id="main-container">
    


    
  <div class="level is-marginless">
    <div class="level-left">
      <h1 class="title is-clearfix">
    
        Showing 1&ndash;50 of 260,284 results for all: <span class="mathjax">machine learning</span>
    
</h1>
    </div>
    <div class="level-right is-hidden-mobile">
      <!-- feedback for mobile is moved to footer -->
      <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
    </div>
  </div>
    <div class="content">
      
  <form method="GET" action="/search/"  aria-role="search">
    

    
    <div class="field has-addons-tablet">
      <div class="control is-expanded">
        <label for="query" class="hidden-label">Search term or terms</label>
        
          <input class="input is-medium" id="query" name="query" placeholder="Search term..." type="text" value="machine learning">
        
        
      </div>
      <div class="select control is-medium">
        <label class="is-hidden" for="searchtype">Field</label>
        <select class="is-medium" id="searchtype" name="searchtype"><option selected value="all">All fields</option><option value="title">Title</option><option value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="license">License (URI)</option><option value="author_id">arXiv author ID</option><option value="help">Help pages</option><option value="full_text">Full text</option></select>
      </div>
      <div class="control">
          <button class="button is-link is-medium">Search</button>
      </div>
    </div>
    <div class="field">
      <div class="control is-size-7">
        
        <label class="radio">
          <input checked id="abstracts-0" name="abstracts" type="radio" value="show"> Show abstracts
        </label>
        
        <label class="radio">
          <input id="abstracts-1" name="abstracts" type="radio" value="hide"> Hide abstracts
        </label>
        
      </div>
    </div>
    <div class="is-clearfix" style="height: 2.5em"> 
      <div class="is-pulled-right">
        
        <a href="/search/advanced?terms-0-term=machine+learning&amp;terms-0-field=all&amp;size=50&amp;order=-announced_date_first">Advanced Search</a>
        
      </div>
    </div>
    <input type="hidden" name="order" value="-announced_date_first">
    <input type="hidden" name="size" value="50">
  </form>

  

  
      
<div class="level breathe-horizontal">
  <div class="level-left">
    <form method="GET" action="/search/">
      <div style="display: none;">
        
          
            <select id="searchtype" name="searchtype"><option selected value="all">All fields</option><option value="title">Title</option><option value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="license">License (URI)</option><option value="author_id">arXiv author ID</option><option value="help">Help pages</option><option value="full_text">Full text</option></select>
          
        
          
            <input id="query" name="query" type="text" value="machine learning">
          
        
          
        
          
        
          
            <ul id="abstracts"><li><input checked id="abstracts-0" name="abstracts" type="radio" value="show"> <label for="abstracts-0">Show abstracts</label></li><li><input id="abstracts-1" name="abstracts" type="radio" value="hide"> <label for="abstracts-1">Hide abstracts</label></li></ul>
          
        
      </div>
      <div class="box field is-grouped is-grouped-multiline level-item">
        <div class="control">
          <span class="select is-small">
            <select id="size" name="size"><option value="25">25</option><option selected value="50">50</option><option value="100">100</option><option value="200">200</option></select>
          </span>
          <label for="size">results per page</label>.
        </div>
        <div class="control">
          <label for="order">Sort results by</label>
          <span class="select is-small">
            <select id="order" name="order"><option selected value="-announced_date_first">Announcement date (newest first)</option><option value="announced_date_first">Announcement date (oldest first)</option><option value="-submitted_date">Submission date (newest first)</option><option value="submitted_date">Submission date (oldest first)</option><option value="">Relevance</option></select>
          </span>
        </div>
        <div class="control">
          <button class="button is-small is-link">Go</button>
        </div>
      </div>
    </form>
  </div>
</div>
      


  <nav class="pagination is-small is-centered breathe-horizontal" role="navigation" aria-label="pagination">
    
    <a href=""
      class="pagination-previous is-invisible">Previous
    </a>
    
    
      <a href="/search/?query=machine+learning&amp;searchtype=all&amp;source=header&amp;start=50"
        class="pagination-next" >Next
      </a>
    
    <ul class="pagination-list">

      <li>
        <a href="/search/?query=machine+learning&amp;searchtype=all&amp;source=header&amp;start=0"
          class="pagination-link is-current"
          aria-label="Goto page 1">1
        </a>
      </li>

      
                                     
          
          <li>
            <a href="/search/?query=machine+learning&amp;searchtype=all&amp;source=header&amp;start=50"
              class="pagination-link "
              aria-label="Page 2"
              aria-current="page">2
            </a>
          </li>
          
          <li>
            <a href="/search/?query=machine+learning&amp;searchtype=all&amp;source=header&amp;start=100"
              class="pagination-link "
              aria-label="Page 3"
              aria-current="page">3
            </a>
          </li>
          
          <li>
            <a href="/search/?query=machine+learning&amp;searchtype=all&amp;source=header&amp;start=150"
              class="pagination-link "
              aria-label="Page 4"
              aria-current="page">4
            </a>
          </li>
          
          <li>
            <a href="/search/?query=machine+learning&amp;searchtype=all&amp;source=header&amp;start=200"
              class="pagination-link "
              aria-label="Page 5"
              aria-current="page">5
            </a>
          </li>
          
          <li><span class="pagination-ellipsis">&hellip;</span></li>
        
      
    </ul>
  </nav>
  



<ol class="breathe-horizontal" start="1"> 


  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06265">arXiv:2504.06265</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06265">pdf</a>, <a href="https://arxiv.org/format/2504.06265">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        GOLLuM: Gaussian Process Optimized LLMs -- Reframing LLM Finetuning through Bayesian Optimization
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Rankovi%C4%87%2C+B">Bojana Ranković</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Schwaller%2C+P">Philippe Schwaller</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06265v1-abstract-short" style="display: inline;">
        &hellip;settings (tuned once on a single dataset). Finally, we explain these improvements: joint LLM-GP optimization through marginal likelihood implicitly performs contrastive <span class="search-hit mathjax">learning</span>, aligning representations to produce (1) better-structured embedding spaces, (2) improved uncertainty calibration, and (3) more efficient sampling - without requiring any external lo&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06265v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06265v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06265v1-abstract-full" style="display: none;">
        Large Language Models (LLMs) can encode complex relationships in their latent spaces, yet harnessing them for optimization under uncertainty remains challenging. We address this gap with a novel architecture that reframes LLM finetuning as Gaussian process (GP) marginal likelihood optimization via deep kernel methods. We introduce LLM-based deep kernels, jointly optimized with GPs to preserve the benefits of both - LLMs to provide a rich and flexible input space for Bayesian optimization and - GPs to model this space with predictive uncertainty for more efficient sampling. Applied to Buchwald-Hartwig reaction optimization, our method nearly doubles the discovery rate of high-performing reactions compared to static LLM embeddings (from 24% to 43% coverage of the top 5% reactions in just 50 optimization iterations). We also observe a 14% improvement over domain-specific representations without requiring specialized features. Extensive empirical evaluation across 19 benchmarks - ranging from general chemistry to reaction and molecular property optimization - demonstrates our method&#39;s robustness, generality, and consistent improvements across: (1) tasks, (2) LLM architectures (encoder, decoder, encoder-decoder), (3) pretraining domains (chemistry-related or general-purpose) and (4) hyperparameter settings (tuned once on a single dataset). Finally, we explain these improvements: joint LLM-GP optimization through marginal likelihood implicitly performs contrastive <span class="search-hit mathjax">learning</span>, aligning representations to produce (1) better-structured embedding spaces, (2) improved uncertainty calibration, and (3) more efficient sampling - without requiring any external loss. This work provides both practical advances in sample-efficient optimization and insights into what makes effective Bayesian optimization.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06265v1-abstract-full').style.display = 'none'; document.getElementById('2504.06265v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06261">arXiv:2504.06261</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06261">pdf</a>, <a href="https://arxiv.org/format/2504.06261">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Hogwild! Inference: Parallel LLM Generation via Concurrent Attention
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Rodionov%2C+G">Gleb Rodionov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Garipov%2C+R">Roman Garipov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shutova%2C+A">Alina Shutova</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yakushev%2C+G">George Yakushev</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Egiazarian%2C+V">Vage Egiazarian</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sinitsin%2C+A">Anton Sinitsin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kuznedelev%2C+D">Denis Kuznedelev</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Alistarh%2C+D">Dan Alistarh</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06261v1-abstract-short" style="display: inline;">
        Large Language Models (LLMs) have demonstrated the ability to tackle increasingly complex tasks through advanced reasoning, long-form content generation, and tool use. Solving these tasks often involves long inference-time computations. In human problem solving, a common strategy to expedite work is collaboration: by dividing the problem into sub-tasks, exploring different strategies concurrently,&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06261v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06261v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06261v1-abstract-full" style="display: none;">
        Large Language Models (LLMs) have demonstrated the ability to tackle increasingly complex tasks through advanced reasoning, long-form content generation, and tool use. Solving these tasks often involves long inference-time computations. In human problem solving, a common strategy to expedite work is collaboration: by dividing the problem into sub-tasks, exploring different strategies concurrently, etc. Recent research has shown that LLMs can also operate in parallel by implementing explicit cooperation frameworks, such as voting mechanisms or the explicit creation of independent sub-tasks that can be executed in parallel. However, each of these frameworks may not be suitable for all types of tasks, which can hinder their applicability. In this work, we propose a different design approach: we run LLM &#34;workers&#34; in parallel , allowing them to synchronize via a concurrently-updated attention cache and prompt these workers to decide how best to collaborate. Our approach allows the instances to come up with their own collaboration strategy for the problem at hand, all the while &#34;seeing&#34; each other&#39;s partial progress in the concurrent cache. We implement this approach via Hogwild! Inference: a parallel LLM inference engine where multiple instances of the same LLM run in parallel with the same attention cache, with &#34;instant&#34; access to each other&#39;s generated tokens. Hogwild! inference takes advantage of Rotary Position Embeddings (RoPE) to avoid recomputation while improving parallel hardware utilization. We find that modern reasoning-capable LLMs can perform inference with shared Key-Value cache out of the box, without additional fine-tuning.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06261v1-abstract-full').style.display = 'none'; document.getElementById('2504.06261v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Preprint, work in progress</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06250">arXiv:2504.06250</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06250">pdf</a>, <a href="https://arxiv.org/format/2504.06250">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Probability">math.PR</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Fractal and Regular Geometry of Deep Neural Networks
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Di+Lillo%2C+S">Simmaco Di Lillo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Marinucci%2C+D">Domenico Marinucci</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Salvi%2C+M">Michele Salvi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vigogna%2C+S">Stefano Vigogna</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06250v1-abstract-short" style="display: inline;">
        We study the geometric properties of random neural networks by investigating the boundary volumes of their excursion sets for different activation functions, as the depth increases. More specifically, we show that, for activations which are not very regular (e.g., the Heaviside step function), the boundary volumes exhibit fractal behavior, with their Hausdorff dimension monotonically increasing wi&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06250v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06250v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06250v1-abstract-full" style="display: none;">
        We study the geometric properties of random neural networks by investigating the boundary volumes of their excursion sets for different activation functions, as the depth increases. More specifically, we show that, for activations which are not very regular (e.g., the Heaviside step function), the boundary volumes exhibit fractal behavior, with their Hausdorff dimension monotonically increasing with the depth. On the other hand, for activations which are more regular (e.g., ReLU, logistic and $\tanh$), as the depth increases, the expected boundary volumes can either converge to zero, remain constant or diverge exponentially, depending on a single spectral parameter which can be easily computed. Our theoretical results are confirmed in some numerical experiments based on Monte Carlo simulations.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06250v1-abstract-full').style.display = 'none'; document.getElementById('2504.06250v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          60G60; 62B10; 62M45; 68T07
        

        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06249">arXiv:2504.06249</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06249">pdf</a>, <a href="https://arxiv.org/format/2504.06249">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Materials Science">cond-mat.mtrl-sci</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Electronic Structure Guided Inverse Design Using Generative Models
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Jia%2C+S">Shuyi Jia</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ganesh%2C+P">Panchapakesan Ganesh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fung%2C+V">Victor Fung</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06249v1-abstract-short" style="display: inline;">
        &hellip;or exhaustive computational screening of known materials remain inefficient and resource-prohibitive for this task. Here, we introduce DOSMatGen, the first instance of a <span class="search-hit mathjax">machine</span> <span class="search-hit mathjax">learning</span> method which generates crystal structures that match a given desired electronic density of states. DOSMatGen is an E(3)-equivariant j&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06249v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06249v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06249v1-abstract-full" style="display: none;">
        The electronic structure of a material fundamentally determines its underlying physical, and by extension, its functional properties. Consequently, the ability to identify or generate materials with desired electronic properties would enable the design of tailored functional materials. Traditional approaches relying on human intuition or exhaustive computational screening of known materials remain inefficient and resource-prohibitive for this task. Here, we introduce DOSMatGen, the first instance of a <span class="search-hit mathjax">machine</span> <span class="search-hit mathjax">learning</span> method which generates crystal structures that match a given desired electronic density of states. DOSMatGen is an E(3)-equivariant joint diffusion framework, and utilizes classifier-free guidance to accurately condition the generated materials on the density of states. Our experiments find this approach can successfully yield materials which are both stable and match closely with the desired density of states. Furthermore, this method is highly flexible and allows for finely controlled generation which can target specific templates or even individual sites within a material. This method enables a more physics-driven approach to designing new materials for applications including catalysts, photovoltaics, and superconductors.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06249v1-abstract-full').style.display = 'none'; document.getElementById('2504.06249v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06235">arXiv:2504.06235</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06235">pdf</a>, <a href="https://arxiv.org/format/2504.06235">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Decentralized Federated Domain Generalization with Style Sharing: A Formal Modeling and Convergence Analysis
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zehtabi%2C+S">Shahryar Zehtabi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Han%2C+D">Dong-Jun Han</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hosseinalipour%2C+S">Seyyedali Hosseinalipour</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Brinton%2C+C+G">Christopher G. Brinton</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06235v1-abstract-short" style="display: inline;">
        Much of the federated <span class="search-hit mathjax">learning</span> (FL) literature focuses on settings where local dataset statistics remain the same between training and testing time. Recent advances in domain generalization (DG) aim to use data from source (training) domains to train a model that generalizes well to data from unseen target (testing) domains. In this paper, we are motivated b&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06235v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06235v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06235v1-abstract-full" style="display: none;">
        Much of the federated <span class="search-hit mathjax">learning</span> (FL) literature focuses on settings where local dataset statistics remain the same between training and testing time. Recent advances in domain generalization (DG) aim to use data from source (training) domains to train a model that generalizes well to data from unseen target (testing) domains. In this paper, we are motivated by two major gaps in existing work on FL and DG: (1) the lack of formal mathematical analysis of DG objectives and training processes; and (2) DG research in FL being limited to the conventional star-topology architecture. Addressing the second gap, we develop $\textit{Decentralized Federated Domain Generalization with Style Sharing}$ ($\texttt{StyleDDG}$), a fully decentralized DG algorithm designed to allow devices in a peer-to-peer network to achieve DG based on sharing style information inferred from their datasets. Additionally, we fill the first gap by providing the first systematic approach to mathematically analyzing style-based DG training optimization. We cast existing centralized DG algorithms within our framework, and employ their formalisms to model $\texttt{StyleDDG}$. Based on this, we obtain analytical conditions under which a sub-linear convergence rate of $\texttt{StyleDDG}$ can be obtained. Through experiments on two popular DG datasets, we demonstrate that $\texttt{StyleDDG}$ can obtain significant improvements in accuracy across target domains with minimal added communication overhead compared to decentralized gradient methods that do not employ style sharing.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06235v1-abstract-full').style.display = 'none'; document.getElementById('2504.06235v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06225">arXiv:2504.06225</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06225">pdf</a>, <a href="https://arxiv.org/format/2504.06225">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Encoder-Decoder Gemma: Improving the Quality-Efficiency Trade-Off via Adaptation
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+B">Biao Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moiseev%2C+F">Fedor Moiseev</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ainslie%2C+J">Joshua Ainslie</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Suganthan%2C+P">Paul Suganthan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+M">Min Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bhupatiraju%2C+S">Surya Bhupatiraju</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lebron%2C+F">Fede Lebron</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Firat%2C+O">Orhan Firat</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Joulin%2C+A">Armand Joulin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dong%2C+Z">Zhe Dong</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06225v1-abstract-short" style="display: inline;">
        While decoder-only large language models (LLMs) have shown impressive results, encoder-decoder models are still widely adopted in real-world applications for their inference efficiency and richer encoder representation. In this paper, we study a novel problem: adapting pretrained decoder-only LLMs to encoder-decoder, with the goal of leveraging the strengths of both approaches to achieve a more fa&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06225v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06225v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06225v1-abstract-full" style="display: none;">
        While decoder-only large language models (LLMs) have shown impressive results, encoder-decoder models are still widely adopted in real-world applications for their inference efficiency and richer encoder representation. In this paper, we study a novel problem: adapting pretrained decoder-only LLMs to encoder-decoder, with the goal of leveraging the strengths of both approaches to achieve a more favorable quality-efficiency trade-off. We argue that adaptation not only enables inheriting the capability of decoder-only LLMs but also reduces the demand for computation compared to pretraining from scratch. We rigorously explore different pretraining objectives and parameter initialization/optimization techniques. Through extensive experiments based on Gemma 2 (2B and 9B) and a suite of newly pretrained mT5-sized models (up to 1.6B), we demonstrate the effectiveness of adaptation and the advantage of encoder-decoder LLMs. Under similar inference budget, encoder-decoder LLMs achieve comparable (often better) pretraining performance but substantially better finetuning performance than their decoder-only counterpart. For example, Gemma 2B-2B outperforms Gemma 2B by $\sim$7\% after instruction tuning. Encoder-decoder adaptation also allows for flexible combination of different-sized models, where Gemma 9B-2B significantly surpasses Gemma 2B-2B by $&gt;$3\%. The adapted encoder representation also yields better results on SuperGLUE. We will release our checkpoints to facilitate future research.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06225v1-abstract-full').style.display = 'none'; document.getElementById('2504.06225v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06219">arXiv:2504.06219</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06219">pdf</a>, <a href="https://arxiv.org/format/2504.06219">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Can Performant LLMs Be Ethical? Quantifying the Impact of Web Crawling Opt-Outs
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Fan%2C+D">Dongyang Fan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sabol%C4%8Dec%2C+V">Vinko Sabolčec</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ansaripour%2C+M">Matin Ansaripour</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tarun%2C+A+K">Ayush Kumar Tarun</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jaggi%2C+M">Martin Jaggi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bosselut%2C+A">Antoine Bosselut</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Schlag%2C+I">Imanol Schlag</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06219v1-abstract-short" style="display: inline;">
        The increasing adoption of web crawling opt-outs by copyright holders of online content raises critical questions about the impact of data compliance on large language model (LLM) performance. However, little is known about how these restrictions (and the resultant filtering of pretraining datasets) affect the capabilities of models trained using these corpora. In this work, we conceptualize this&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06219v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06219v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06219v1-abstract-full" style="display: none;">
        The increasing adoption of web crawling opt-outs by copyright holders of online content raises critical questions about the impact of data compliance on large language model (LLM) performance. However, little is known about how these restrictions (and the resultant filtering of pretraining datasets) affect the capabilities of models trained using these corpora. In this work, we conceptualize this effect as the $\textit{data compliance gap}$ (DCG), which quantifies the performance difference between models trained on datasets that comply with web crawling opt-outs, and those that do not. We measure the data compliance gap in two settings: pretraining models from scratch and continual pretraining from existing compliant models (simulating a setting where copyrighted data could be integrated later in pretraining). Our experiments with 1.5B models show that, as of January 2025, compliance with web data opt-outs does not degrade general knowledge acquisition (close to 0\% DCG). However, in specialized domains such as biomedical research, excluding major publishers leads to performance declines. These findings suggest that while general-purpose LLMs can be trained to perform equally well using fully open data, performance in specialized domains may benefit from access to high-quality copyrighted sources later in training. Our study provides empirical insights into the long-debated trade-off between data compliance and downstream model performance, informing future discussions on AI training practices and policy decisions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06219v1-abstract-full').style.display = 'none'; document.getElementById('2504.06219v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06217">arXiv:2504.06217</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06217">pdf</a>, <a href="https://arxiv.org/format/2504.06217">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Quantum Physics">quant-ph</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optics">physics.optics</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Chernoff Information Bottleneck for Covert Quantum Target Sensing
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ortolano%2C+G">Giuseppe Ortolano</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ruo-Berchera%2C+I">Ivano Ruo-Berchera</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Banchi%2C+L">Leonardo Banchi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06217v1-abstract-short" style="display: inline;">
        &hellip;to assess and quantify quantum advantage in covert situations. This is based on extending the information bottleneck principle, originally developed for communication and <span class="search-hit mathjax">machine</span> <span class="search-hit mathjax">learning</span> applications, to decision problems via the Chernoff information, with the ultimate goal of quantitatively optimizing the trade-off b&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06217v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06217v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06217v1-abstract-full" style="display: none;">
        Target sensing is a fundamental task with many practical applications, e.g.~in LiDaR and radar systems. Quantum strategies with entangled states can achieve better sensing accuracies with the same probe energy, yet it is often simpler to use classical probes with higher energy than to take advantage of the quantum regime. Recently, it has been shown that useful quantum advantage can be achieved in covert situations, where sensing has to be performed while also avoiding detection by an adversary: here increasing energy is not a viable stratagem, as it facilitates the adversary. In this paper we introduce a general framework to assess and quantify quantum advantage in covert situations. This is based on extending the information bottleneck principle, originally developed for communication and <span class="search-hit mathjax">machine</span> <span class="search-hit mathjax">learning</span> applications, to decision problems via the Chernoff information, with the ultimate goal of quantitatively optimizing the trade-off between covertness and sensing ability. In this context we show how quantum resources, namely entangled photonic probes paired with photon counting, greatly outperform classical coherent transmitters in target detection and ranging, while also maintaining a chosen level of covertness. Our work highlights the great potential of integrating quantum sensing in LiDAR systems to enhance the covert performance.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06217v1-abstract-full').style.display = 'none'; document.getElementById('2504.06217v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06214">arXiv:2504.06214</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06214">pdf</a>, <a href="https://arxiv.org/format/2504.06214">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        From 128K to 4M: Efficient Training of Ultra-Long Context Large Language Models
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Xu%2C+C">Chejian Xu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ping%2C+W">Wei Ping</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xu%2C+P">Peng Xu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Z">Zihan Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+B">Boxin Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shoeybi%2C+M">Mohammad Shoeybi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+B">Bo Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Catanzaro%2C+B">Bryan Catanzaro</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06214v1-abstract-short" style="display: inline;">
        Long-context capabilities are essential for a wide range of applications, including document and video understanding, in-context <span class="search-hit mathjax">learning</span>, and inference-time scaling, all of which require models to process and reason over long sequences of text and multimodal data. In this work, we introduce a efficient training recipe for building ultra-long context LLMs fr&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06214v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06214v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06214v1-abstract-full" style="display: none;">
        Long-context capabilities are essential for a wide range of applications, including document and video understanding, in-context <span class="search-hit mathjax">learning</span>, and inference-time scaling, all of which require models to process and reason over long sequences of text and multimodal data. In this work, we introduce a efficient training recipe for building ultra-long context LLMs from aligned instruct model, pushing the boundaries of context lengths from 128K to 1M, 2M, and 4M tokens. Our approach leverages efficient continued pretraining strategies to extend the context window and employs effective instruction tuning to maintain the instruction-following and reasoning abilities. Our UltraLong-8B, built on Llama3.1-Instruct with our recipe, achieves state-of-the-art performance across a diverse set of long-context benchmarks. Importantly, models trained with our approach maintain competitive performance on standard benchmarks, demonstrating balanced improvements for both long and short context tasks. We further provide an in-depth analysis of key design choices, highlighting the impacts of scaling strategies and data composition. Our findings establish a robust framework for efficiently scaling context lengths while preserving general model capabilities. We release all model weights at: https://ultralong.github.io/.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06214v1-abstract-full').style.display = 'none'; document.getElementById('2504.06214v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06212">arXiv:2504.06212</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06212">pdf</a>, <a href="https://arxiv.org/format/2504.06212">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Applications">stat.AP</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        NNN: Next-Generation Neural Networks for Marketing Mix Modeling
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Mulc%2C+T">Thomas Mulc</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Anderson%2C+M">Mike Anderson</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cubre%2C+P">Paul Cubre</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+H">Huikun Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+I">Ivy Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kumar%2C+S">Saket Kumar</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06212v1-abstract-short" style="display: inline;">
        We present NNN, a Transformer-based neural network approach to Marketing Mix Modeling (MMM) designed to address key limitations of traditional methods. Unlike conventional MMMs which rely on scalar inputs and parametric decay functions, NNN uses rich embeddings to capture both quantitative and qualitative aspects of marketing and organic channels (e.g., search queries, ad creatives). This, combine&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06212v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06212v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06212v1-abstract-full" style="display: none;">
        We present NNN, a Transformer-based neural network approach to Marketing Mix Modeling (MMM) designed to address key limitations of traditional methods. Unlike conventional MMMs which rely on scalar inputs and parametric decay functions, NNN uses rich embeddings to capture both quantitative and qualitative aspects of marketing and organic channels (e.g., search queries, ad creatives). This, combined with its attention mechanism, enables NNN to model complex interactions, capture long-term effects, and potentially improve sales attribution accuracy. We show that L1 regularization permits the use of such expressive models in typical data-constrained settings. Evaluating NNN on simulated and real-world data demonstrates its efficacy, particularly through considerable improvement in predictive power. Beyond attribution, NNN provides valuable, complementary insights through model probing, such as evaluating keyword or creative effectiveness, enhancing model interpretability.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06212v1-abstract-full').style.display = 'none'; document.getElementById('2504.06212v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06211">arXiv:2504.06211</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06211">pdf</a>, <a href="https://arxiv.org/format/2504.06211">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Hardware Architecture">cs.AR</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Cryptography and Security">cs.CR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Need for zkSpeed: Accelerating HyperPlonk for Zero-Knowledge Proofs
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Daftardar%2C+A">Alhad Daftardar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mo%2C+J">Jianqiao Mo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ah-kiow%2C+J">Joey Ah-kiow</a>, 
      
      <a href="/search/?searchtype=author&amp;query=B%C3%BCnz%2C+B">Benedikt Bünz</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Karri%2C+R">Ramesh Karri</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Garg%2C+S">Siddharth Garg</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Reagen%2C+B">Brandon Reagen</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06211v1-abstract-short" style="display: inline;">
        &hellip;enable a proving party to prove the truth of a statement to a verifying party without revealing anything else. ZKPs have applications in blockchain technologies, verifiable <span class="search-hit mathjax">machine</span> <span class="search-hit mathjax">learning</span>, and electronic voting, but have yet to see widespread adoption due to the computational complexity of the proving process. Recent&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06211v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06211v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06211v1-abstract-full" style="display: none;">
        Zero-Knowledge Proofs (ZKPs) are rapidly gaining importance in privacy-preserving and verifiable computing. ZKPs enable a proving party to prove the truth of a statement to a verifying party without revealing anything else. ZKPs have applications in blockchain technologies, verifiable <span class="search-hit mathjax">machine</span> <span class="search-hit mathjax">learning</span>, and electronic voting, but have yet to see widespread adoption due to the computational complexity of the proving process. Recent works have accelerated the key primitives of state-of-the-art ZKP protocols on GPU and ASIC. However, the protocols accelerated thus far face one of two challenges: they either require a trusted setup for each application, or they generate larger proof sizes with higher verification costs, limiting their applicability in scenarios with numerous verifiers or strict verification time constraints. This work presents an accelerator, zkSpeed, for HyperPlonk, a state-of-the-art ZKP protocol that supports both one-time, universal setup and small proof sizes for typical ZKP applications in publicly verifiable, consensus-based systems. We accelerate the entire protocol, including two major primitives: SumCheck and Multi-scalar Multiplications (MSMs). We develop a full-chip architecture using 366.46 mm$^2$ and 2 TB/s of bandwidth to accelerate the entire proof generation process, achieving geometric mean speedups of 801$\times$ over CPU baselines.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06211v1-abstract-full').style.display = 'none'; document.getElementById('2504.06211v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Preprint, 15 pages, 14 figures, accepted to the 52nd International Symposium on Computer Architecture (ISCA), 2025</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06209">arXiv:2504.06209</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06209">pdf</a>, <a href="https://arxiv.org/format/2504.06209">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Statistical Mechanics">cond-mat.stat-mech</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Theory">cs.IT</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Adaptation and Self-Organizing Systems">nlin.AO</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Chaotic Dynamics">nlin.CD</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Quantum Physics">quant-ph</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        The Work Capacity of Channels with Memory: Maximum Extractable Work in Percept-Action Loops
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Fiderer%2C+L+J">Lukas J. Fiderer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Barth%2C+P+C">Paul C. Barth</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Smith%2C+I+D">Isaac D. Smith</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Briegel%2C+H+J">Hans J. Briegel</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06209v1-abstract-short" style="display: inline;">
        Predicting future observations plays a central role in <span class="search-hit mathjax">machine</span>&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06209v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06209v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06209v1-abstract-full" style="display: none;">
        Predicting future observations plays a central role in <span class="search-hit mathjax">machine</span> <span class="search-hit mathjax">learning</span>, biology, economics, and many other fields. It lies at the heart of organizational principles such as the variational free energy principle and has even been shown -- based on the second law of thermodynamics -- to be necessary for reaching the fundamental energetic limits of sequential information processing. While the usefulness of the predictive paradigm is undisputed, complex adaptive systems that interact with their environment are more than just predictive <span class="search-hit mathjax">machines</span>: they have the power to act upon their environment and cause change. In this work, we develop a framework to analyze the thermodynamics of information processing in percept-action loops -- a model of agent-environment interaction -- allowing us to investigate the thermodynamic implications of actions and percepts on equal footing. To this end, we introduce the concept of work capacity -- the maximum rate at which an agent can expect to extract work from its environment. Our results reveal that neither of two previously established design principles for work-efficient agents -- maximizing predictive power and forgetting past actions -- remains optimal in environments where actions have observable consequences. Instead, a trade-off emerges: work-efficient agents must balance prediction and forgetting, as remembering past actions can reduce the available free energy. This highlights a fundamental departure from the thermodynamics of passive observation, suggesting that prediction and energy efficiency may be at odds in active <span class="search-hit mathjax">learning</span> systems.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06209v1-abstract-full').style.display = 'none'; document.getElementById('2504.06209v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">10+32 pages; 6+19 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06207">arXiv:2504.06207</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06207">pdf</a>, <a href="https://arxiv.org/format/2504.06207">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        An experimental survey and Perspective View on Meta-<span class="search-hit mathjax">Learning</span> for Automated Algorithms Selection and Parametrization
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Garouani%2C+M">Moncef Garouani</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06207v1-abstract-short" style="display: inline;">
        &hellip;progress has been made in the recent literature studies to tackle the Algorithms Selection and Parametrization (ASP) problem, which is diversified in multiple meta-<span class="search-hit mathjax">learning</span> setups. Yet there is a lack of surveys and comparative evaluations that critically analyze, summarize and assess the performance of existing methods. In this paper, we provide an overview&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06207v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06207v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06207v1-abstract-full" style="display: none;">
        Considerable progress has been made in the recent literature studies to tackle the Algorithms Selection and Parametrization (ASP) problem, which is diversified in multiple meta-<span class="search-hit mathjax">learning</span> setups. Yet there is a lack of surveys and comparative evaluations that critically analyze, summarize and assess the performance of existing methods. In this paper, we provide an overview of the state of the art in this continuously evolving field. The survey sheds light on the motivational reasons for pursuing classifiers selection through meta-<span class="search-hit mathjax">learning</span>. In this regard, Automated <span class="search-hit mathjax">Machine</span> <span class="search-hit mathjax">Learning</span> (AutoML) is usually treated as an ASP problem under the umbrella of the democratization of <span class="search-hit mathjax">machine</span> <span class="search-hit mathjax">learning</span>. Accordingly, AutoML makes <span class="search-hit mathjax">machine</span> <span class="search-hit mathjax">learning</span> techniques accessible to domain scientists who are interested in applying advanced analytics but lack the required expertise. It can ease the task of manually selecting ML algorithms and tuning related hyperparameters. We comprehensively discuss the different phases of classifiers selection based on a generic framework that is formed as an outcome of reviewing prior works. Subsequently, we propose a benchmark knowledge base of 4 millions previously <span class="search-hit mathjax">learned</span> models and present extensive comparative evaluations of the prominent methods for classifiers selection based on 08 classification algorithms and 400 benchmark datasets. The comparative study quantitatively assesses the performance of algorithms selection methods along while emphasizing the strengths and limitations of existing studies.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06207v1-abstract-full').style.display = 'none'; document.getElementById('2504.06207v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06196">arXiv:2504.06196</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06196">pdf</a>, <a href="https://arxiv.org/format/2504.06196">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        TxGemma: Efficient and Agentic LLMs for Therapeutics
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+E">Eric Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Schmidgall%2C+S">Samuel Schmidgall</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jaeger%2C+P+F">Paul F. Jaeger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+F">Fan Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pilgrim%2C+R">Rory Pilgrim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Matias%2C+Y">Yossi Matias</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Barral%2C+J">Joelle Barral</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fleet%2C+D">David Fleet</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Azizi%2C+S">Shekoofeh Azizi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06196v1-abstract-short" style="display: inline;">
        Therapeutic development is a costly and high-risk endeavor that is often plagued by high failure rates. To address this, we introduce TxGemma, a suite of efficient, generalist large language models (LLMs) capable of therapeutic property prediction as well as interactive reasoning and explainability. Unlike task-specific models, TxGemma synthesizes information from diverse sources, enabling broad a&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06196v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06196v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06196v1-abstract-full" style="display: none;">
        Therapeutic development is a costly and high-risk endeavor that is often plagued by high failure rates. To address this, we introduce TxGemma, a suite of efficient, generalist large language models (LLMs) capable of therapeutic property prediction as well as interactive reasoning and explainability. Unlike task-specific models, TxGemma synthesizes information from diverse sources, enabling broad application across the therapeutic development pipeline. The suite includes 2B, 9B, and 27B parameter models, fine-tuned from Gemma-2 on a comprehensive dataset of small molecules, proteins, nucleic acids, diseases, and cell lines. Across 66 therapeutic development tasks, TxGemma achieved superior or comparable performance to the state-of-the-art generalist model on 64 (superior on 45), and against state-of-the-art specialist models on 50 (superior on 26). Fine-tuning TxGemma models on therapeutic downstream tasks, such as clinical trial adverse event prediction, requires less training data than fine-tuning base LLMs, making TxGemma suitable for data-limited applications. Beyond these predictive capabilities, TxGemma features conversational models that bridge the gap between general LLMs and specialized property predictors. These allow scientists to interact in natural language, provide mechanistic reasoning for predictions based on molecular structure, and engage in scientific discussions. Building on this, we further introduce Agentic-Tx, a generalist therapeutic agentic system powered by Gemini 2.5 that reasons, acts, manages diverse workflows, and acquires external domain knowledge. Agentic-Tx surpasses prior leading models on the Humanity&#39;s Last Exam benchmark (Chemistry &amp; Biology) with 52.3% relative improvement over o3-mini (high) and 26.7% over o3-mini (high) on GPQA (Chemistry) and excels with improvements of 6.3% (ChemBench-Preference) and 2.4% (ChemBench-Mini) over o3-mini (high).
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06196v1-abstract-full').style.display = 'none'; document.getElementById('2504.06196v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06195">arXiv:2504.06195</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06195">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optics">physics.optics</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Medical Physics">physics.med-ph</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Quantitative Methods">q-bio.QM</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Accuracy Enhancement in Refractive Index Sensing via Full-Spectrum <span class="search-hit mathjax">Machine</span> <span class="search-hit mathjax">Learning</span> Modeling
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Aalizadeh%2C+M">Majid Aalizadeh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Raut%2C+C">Chinmay Raut</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Afshar%2C+M+A">Morteza Azmoudeh Afshar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tabartehfarahani%2C+A">Ali Tabartehfarahani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fan%2C+X">Xudong Fan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06195v1-abstract-short" style="display: inline;">
        We present a full-spectrum <span class="search-hit mathjax">machine</span> <span class="search-hit mathjax">learning</span> framework for refractive index sensing using simulated absorption spectra from meta-grating structures composed of titanium or silicon nanorods under TE and TM polarizations. Linear regression was applied to 80 principal components extracted from each spectrum, and model perf&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06195v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06195v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06195v1-abstract-full" style="display: none;">
        We present a full-spectrum <span class="search-hit mathjax">machine</span> <span class="search-hit mathjax">learning</span> framework for refractive index sensing using simulated absorption spectra from meta-grating structures composed of titanium or silicon nanorods under TE and TM polarizations. Linear regression was applied to 80 principal components extracted from each spectrum, and model performance was assessed using five-fold cross-validation, simulating real-world biosensing scenarios where unknown patient samples are predicted based on standard calibration data. Titanium-based structures, dominated by broadband intensity changes, yielded the lowest mean squared errors and the highest accuracy improvements: up to a 6065-fold reduction compared to the best single-feature model. In contrast, silicon-based structures, governed by narrow resonances, showed more modest gains due to spectral nonlinearity that limits the effectiveness of global linear models. We also show that even the best single-wavelength predictor is identified through data-driven analysis, not visual selection, highlighting the value of automated feature preselection. These findings demonstrate that spectral shape plays a key role in modeling performance and that full-spectrum linear approaches are especially effective for intensity-modulated index sensors.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06195v1-abstract-full').style.display = 'none'; document.getElementById('2504.06195v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">21 pages, 8 figures, 1 table</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06193">arXiv:2504.06193</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06193">pdf</a>, <a href="https://arxiv.org/format/2504.06193">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Heuristic Methods are Good Teachers to Distill MLPs for Graph Link Prediction
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Qin%2C+Z">Zongyue Qin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+S">Shichang Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ju%2C+M">Mingxuan Ju</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhao%2C+T">Tong Zhao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shah%2C+N">Neil Shah</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sun%2C+Y">Yizhou Sun</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06193v1-abstract-short" style="display: inline;">
        Link prediction is a crucial graph-<span class="search-hit mathjax">learning</span> task with applications including citation prediction and product recommendation. Distilling Graph Neural Networks (GNNs) teachers into Multi-Layer Perceptrons (MLPs) students has emerged as an effective approach to achieve strong performance and reducing computational cost by removing graph dependency. However, exi&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06193v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06193v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06193v1-abstract-full" style="display: none;">
        Link prediction is a crucial graph-<span class="search-hit mathjax">learning</span> task with applications including citation prediction and product recommendation. Distilling Graph Neural Networks (GNNs) teachers into Multi-Layer Perceptrons (MLPs) students has emerged as an effective approach to achieve strong performance and reducing computational cost by removing graph dependency. However, existing distillation methods only use standard GNNs and overlook alternative teachers such as specialized model for link prediction (GNN4LP) and heuristic methods (e.g., common neighbors). This paper first explores the impact of different teachers in GNN-to-MLP distillation. Surprisingly, we find that stronger teachers do not always produce stronger students: MLPs distilled from GNN4LP can underperform those distilled from simpler GNNs, while weaker heuristic methods can teach MLPs to near-GNN performance with drastically reduced training costs. Building on these insights, we propose Ensemble Heuristic-Distilled MLPs (EHDM), which eliminates graph dependencies while effectively integrating complementary signals via a gating mechanism. Experiments on ten datasets show an average 7.93% improvement over previous GNN-to-MLP approaches with 1.95-3.32 times less training time, indicating EHDM is an efficient and effective link prediction method.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06193v1-abstract-full').style.display = 'none'; document.getElementById('2504.06193v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06185">arXiv:2504.06185</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06185">pdf</a>, <a href="https://arxiv.org/format/2504.06185">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        WoundAmbit: Bridging State-of-the-Art Semantic Segmentation and Real-World Wound Care
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Borst%2C+V">Vanessa Borst</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dittus%2C+T">Timo Dittus</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dege%2C+T">Tassilo Dege</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Schmieder%2C+A">Astrid Schmieder</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kounev%2C+S">Samuel Kounev</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06185v1-abstract-short" style="display: inline;">
        &hellip;Semantic segmentation is key to this process, yet wound segmentation remains underrepresented in medical imaging research. To address this, we benchmark state-of-the-art deep <span class="search-hit mathjax">learning</span> models from general-purpose vision, medical imaging, and top methods from public wound challenges. For fair comparison, we standardize training, data augmentation, and evaluat&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06185v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06185v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06185v1-abstract-full" style="display: none;">
        Chronic wounds affect a large population, particularly the elderly and diabetic patients, who often exhibit limited mobility and co-existing health conditions. Automated wound monitoring via mobile image capture can reduce in-person physician visits by enabling remote tracking of wound size. Semantic segmentation is key to this process, yet wound segmentation remains underrepresented in medical imaging research. To address this, we benchmark state-of-the-art deep <span class="search-hit mathjax">learning</span> models from general-purpose vision, medical imaging, and top methods from public wound challenges. For fair comparison, we standardize training, data augmentation, and evaluation, conducting cross-validationto minimize partitioning bias. We also assess real-world deployment aspects, including generalization to an out-of-distribution wound dataset, computational efficiency, and interpretability. Additionally, we propose a reference object-based approach to convert AI-generated masks into clinically relevant wound size estimates, and evaluate this, along with mask quality, for the best models based on physician assessments. Overall, the transformer-based TransNeXt showed the highest levels of generalizability. Despite variations in inference times, all models processed at least one image per second on the CPU, which is deemed adequate for the intended application. Interpretability analysis typically revealed prominent activations in wound regions, emphasizing focus on clinically relevant features. Expert evaluation showed high mask approval for all analyzed models, with VWFormer and ConvNeXtS backbone performing the best. Size retrieval accuracy was similar across models, and predictions closely matched expert annotations. Finally, we demonstrate how our AI-driven wound size estimation framework, WoundAmbit, can be integrated into a custom telehealth system. Our code will be made available on GitHub upon publication.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06185v1-abstract-full').style.display = 'none'; document.getElementById('2504.06185v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Main paper: 17 pages; supplementary material: 16 pages; paper submitted to the application track of the European Conference on <span class="search-hit mathjax">Machine</span> <span class="search-hit mathjax">Learning</span> and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD 2025)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06176">arXiv:2504.06176</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06176">pdf</a>, <a href="https://arxiv.org/format/2504.06176">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Space Physics">physics.space-ph</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Self-Supervised Framework for Space Object Behaviour Characterisation
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Groves%2C+I">Ian Groves</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Campbell%2C+A">Andrew Campbell</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fernandes%2C+J">James Fernandes</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rodriguez%2C+D">Diego Rodriguez</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Murray%2C+P">Paul Murray</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vasile%2C+M">Massimiliano Vasile</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nockles%2C+V">Victoria Nockles</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06176v1-abstract-short" style="display: inline;">
        &hellip;anomaly predictions on real data revealed distinct patterns including characteristic object profiles and satellite glinting. Here, we demonstrate how self-supervised <span class="search-hit mathjax">learning</span> can simultaneously enable anomaly detection, motion prediction, and synthetic data generation from rich representations <span class="search-hit mathjax">learned</span> in pre-training.&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06176v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06176v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06176v1-abstract-full" style="display: none;">
        Foundation Models, pre-trained on large unlabelled datasets before task-specific fine-tuning, are increasingly being applied to specialised domains. Recent examples include ClimaX for climate and Clay for satellite Earth observation, but a Foundation Model for Space Object Behavioural Analysis has not yet been developed. As orbital populations grow, automated methods for characterising space object behaviour are crucial for space safety. We present a Space Safety and Sustainability Foundation Model focusing on space object behavioural analysis using light curves (LCs). We implemented a Perceiver-Variational Autoencoder (VAE) architecture, pre-trained with self-supervised reconstruction and masked reconstruction on 227,000 LCs from the MMT-9 observatory. The VAE enables anomaly detection, motion prediction, and LC generation. We fine-tuned the model for anomaly detection &amp; motion prediction using two independent LC simulators (CASSANDRA and GRIAL respectively), using CAD models of boxwing, Sentinel-3, SMOS, and Starlink platforms. Our pre-trained model achieved a reconstruction error of 0.01%, identifying potentially anomalous light curves through reconstruction difficulty. After fine-tuning, the model scored 88% and 82% accuracy, with 0.90 and 0.95 ROC AUC scores respectively in both anomaly detection and motion mode prediction (sun-pointing, spin, etc.). Analysis of high-confidence anomaly predictions on real data revealed distinct patterns including characteristic object profiles and satellite glinting. Here, we demonstrate how self-supervised <span class="search-hit mathjax">learning</span> can simultaneously enable anomaly detection, motion prediction, and synthetic data generation from rich representations <span class="search-hit mathjax">learned</span> in pre-training. Our work therefore supports space safety and sustainability through automated monitoring and simulation capabilities.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06176v1-abstract-full').style.display = 'none'; document.getElementById('2504.06176v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">15 pages, 10 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06173">arXiv:2504.06173</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06173">pdf</a>, <a href="https://arxiv.org/format/2504.06173">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Networking and Internet Architecture">cs.NI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Emerging Technologies">cs.ET</span>
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Signal Processing">eess.SP</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1109/TCCN.2025.3558026">10.1109/TCCN.2025.3558026 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Multi-Modality Sensing in mmWave Beamforming for Connected Vehicles Using Deep <span class="search-hit mathjax">Learning</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Mollah%2C+M+B">Muhammad Baqer Mollah</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+H">Honggang Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Karim%2C+M+A">Mohammad Ataul Karim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fang%2C+H">Hua Fang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06173v1-abstract-short" style="display: inline;">
        &hellip;utilizing out-of-band contextual information, such as sensing data obtained from sensor devices, provides a better alternative to reduce overheads. This paper presents a deep <span class="search-hit mathjax">learning</span>-based solution for utilizing the multi-modality sensing data for predicting the optimal beams having sufficient mmWave received powers so that the best V2I and V2V line-of-sig&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06173v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06173v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06173v1-abstract-full" style="display: none;">
        Beamforming techniques are considered as essential parts to compensate severe path losses in millimeter-wave (mmWave) communications. In particular, these techniques adopt large antenna arrays and formulate narrow beams to obtain satisfactory received powers. However, performing accurate beam alignment over narrow beams for efficient link configuration by traditional standard defined beam selection approaches, which mainly rely on channel state information and beam sweeping through exhaustive searching, imposes computational and communications overheads. And, such resulting overheads limit their potential use in vehicle-to-infrastructure (V2I) and vehicle-to-vehicle (V2V) communications involving highly dynamic scenarios. In comparison, utilizing out-of-band contextual information, such as sensing data obtained from sensor devices, provides a better alternative to reduce overheads. This paper presents a deep <span class="search-hit mathjax">learning</span>-based solution for utilizing the multi-modality sensing data for predicting the optimal beams having sufficient mmWave received powers so that the best V2I and V2V line-of-sight links can be ensured proactively. The proposed solution has been tested on real-world measured mmWave sensing and communication data, and the results show that it can achieve up to 98.19% accuracies while predicting top-13 beams. Correspondingly, when compared to existing been sweeping approach, the beam sweeping searching space and time overheads are greatly shortened roughly by 79.67% and 91.89%, respectively which confirm a promising solution for beamforming in mmWave enabled communications.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06173v1-abstract-full').style.display = 'none'; document.getElementById('2504.06173v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">15 Pages</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        IEEE Transactions on Cognitive Communications and Networking, 2025
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06160">arXiv:2504.06160</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06160">pdf</a>, <a href="https://arxiv.org/format/2504.06160">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Social and Information Networks">cs.SI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Navigating the Rabbit Hole: Emergent Biases in LLM-Generated Attack Narratives Targeting Mental Health Groups
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Magu%2C+R">Rijul Magu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dutta%2C+A">Arka Dutta</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kim%2C+S">Sean Kim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=KhudaBukhsh%2C+A+R">Ashiqur R. KhudaBukhsh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=De+Choudhury%2C+M">Munmun De Choudhury</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06160v1-abstract-short" style="display: inline;">
        Large Language Models (LLMs) have been shown to demonstrate imbalanced biases against certain groups. However, the study of unprovoked targeted attacks by LLMs towards at-risk populations remains underexplored. Our paper presents three novel contributions: (1) the explicit evaluation of LLM-generated attacks on highly vulnerable mental health groups; (2) a network-based framework to study the prop&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06160v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06160v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06160v1-abstract-full" style="display: none;">
        Large Language Models (LLMs) have been shown to demonstrate imbalanced biases against certain groups. However, the study of unprovoked targeted attacks by LLMs towards at-risk populations remains underexplored. Our paper presents three novel contributions: (1) the explicit evaluation of LLM-generated attacks on highly vulnerable mental health groups; (2) a network-based framework to study the propagation of relative biases; and (3) an assessment of the relative degree of stigmatization that emerges from these attacks. Our analysis of a recently released large-scale bias audit dataset reveals that mental health entities occupy central positions within attack narrative networks, as revealed by a significantly higher mean centrality of closeness (p-value = 4.06e-10) and dense clustering (Gini coefficient = 0.7). Drawing from sociological foundations of stigmatization theory, our stigmatization analysis indicates increased labeling components for mental health disorder-related targets relative to initial targets in generation chains. Taken together, these insights shed light on the structural predilections of large language models to heighten harmful discourse and highlight the need for suitable approaches for mitigation.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06160v1-abstract-full').style.display = 'none'; document.getElementById('2504.06160v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          J.4; K.4.1; K.4.2
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06157">arXiv:2504.06157</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06157">pdf</a>, <a href="https://arxiv.org/format/2504.06157">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Hall Effect Thruster Forecasting using a Topological Approach for Data Assimilation
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Chumley%2C+M+M">Max M. Chumley</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Khasawneh%2C+F+A">Firas A. Khasawneh</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06157v1-abstract-short" style="display: inline;">
        Hall Effect Thrusters (HETs) are electric thrusters that eject heavy ionized gas particles from the spacecraft to generate thrust. Although traditionally they were used for station keeping, recently They have been used for interplanetary space missions due to their high delta-V potential and their operational longevity in contrast to other thrusters, e.g., chemical. However, the operation of HETs&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06157v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06157v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06157v1-abstract-full" style="display: none;">
        Hall Effect Thrusters (HETs) are electric thrusters that eject heavy ionized gas particles from the spacecraft to generate thrust. Although traditionally they were used for station keeping, recently They have been used for interplanetary space missions due to their high delta-V potential and their operational longevity in contrast to other thrusters, e.g., chemical. However, the operation of HETs involves complex processes such as ionization of gases, strong magnetic fields, and complicated solar panel power supply interactions. Therefore, their operation is extremely difficult to model thus necessitating Data Assimilation (DA) approaches for estimating and predicting their operational states. Because HET&#39;s operating environment is often noisy with non-Gaussian sources, this significantly limits applicable DA tools. We describe a topological approach for data assimilation that bypasses these limitations that does not depend on the noise model, and utilize it to forecast spatiotemporal plume field states of HETs. Our approach is a generalization of the Topological Approach for Data Assimilation (TADA) method that allows including different forecast functions. We show how TADA can be combined with the Long Short-Term Memory network for accurate forecasting. We then apply our approach to high-fidelity Hall Effect Thruster (HET) simulation data from the Air Force Research Laboratory (AFRL) rocket propulsion division where we demonstrate the forecast resiliency of TADA on noise contaminated, high-dimensional data.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06157v1-abstract-full').style.display = 'none'; document.getElementById('2504.06157v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">12 pages, 13 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06141">arXiv:2504.06141</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06141">pdf</a>, <a href="https://arxiv.org/format/2504.06141">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Adversarial Training of Reward Models
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Bukharin%2C+A">Alexander Bukharin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Qian%2C+H">Haifeng Qian</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sun%2C+S">Shengyang Sun</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Renduchintala%2C+A">Adithya Renduchintala</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Singhal%2C+S">Soumye Singhal</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Z">Zhilin Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kuchaiev%2C+O">Oleksii Kuchaiev</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Delalleau%2C+O">Olivier Delalleau</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhao%2C+T">Tuo Zhao</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06141v1-abstract-short" style="display: inline;">
        &hellip;that automatically identifies adversarial examples -- responses that receive high rewards from the target RM but are OOD and of low quality. By leveraging reinforcement <span class="search-hit mathjax">learning</span>, Adv-RM trains a policy to generate adversarial examples that reliably expose vulnerabilities in large state-of-the-art reward models such as Nemotron 340B RM. Incorporating these ad&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06141v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06141v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06141v1-abstract-full" style="display: none;">
        Reward modeling has emerged as a promising approach for the scalable alignment of language models. However, contemporary reward models (RMs) often lack robustness, awarding high rewards to low-quality, out-of-distribution (OOD) samples. This can lead to reward hacking, where policies exploit unintended shortcuts to maximize rewards, undermining alignment. To address this challenge, we introduce Adv-RM, a novel adversarial training framework that automatically identifies adversarial examples -- responses that receive high rewards from the target RM but are OOD and of low quality. By leveraging reinforcement <span class="search-hit mathjax">learning</span>, Adv-RM trains a policy to generate adversarial examples that reliably expose vulnerabilities in large state-of-the-art reward models such as Nemotron 340B RM. Incorporating these adversarial examples into the reward training process improves the robustness of RMs, mitigating reward hacking and enhancing downstream performance in RLHF. We demonstrate that Adv-RM significantly outperforms conventional RM training, increasing stability and enabling more effective RLHF training in both synthetic and real-data settings.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06141v1-abstract-full').style.display = 'none'; document.getElementById('2504.06141v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">16 pages, 7 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06126">arXiv:2504.06126</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06126">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Accelerating Vehicle Routing via AI-Initialized Genetic Algorithms
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Greenberg%2C+I">Ido Greenberg</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sielski%2C+P">Piotr Sielski</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Linsenmaier%2C+H">Hugo Linsenmaier</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gandham%2C+R">Rajesh Gandham</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mannor%2C+S">Shie Mannor</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fender%2C+A">Alex Fender</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chechik%2C+G">Gal Chechik</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Meirom%2C+E">Eli Meirom</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06126v1-abstract-short" style="display: inline;">
        &hellip;yet current state-of-the-art solvers treat each instance on its own without leveraging previous examples. We introduce a novel optimization framework that uses a reinforcement <span class="search-hit mathjax">learning</span> agent - trained on prior instances - to quickly generate initial solutions, which are then further optimized by genetic algorithms. Our framework, Evolutionary Algorithm with&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06126v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06126v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06126v1-abstract-full" style="display: none;">
        Vehicle Routing Problems (VRP) are an extension of the Traveling Salesperson Problem and are a fundamental NP-hard challenge in combinatorial optimization. Solving VRP in real-time at large scale has become critical in numerous applications, from growing markets like last-mile delivery to emerging use-cases like interactive logistics planning. Such applications involve solving similar problem instances repeatedly, yet current state-of-the-art solvers treat each instance on its own without leveraging previous examples. We introduce a novel optimization framework that uses a reinforcement <span class="search-hit mathjax">learning</span> agent - trained on prior instances - to quickly generate initial solutions, which are then further optimized by genetic algorithms. Our framework, Evolutionary Algorithm with Reinforcement <span class="search-hit mathjax">Learning</span> Initialization (EARLI), consistently outperforms current state-of-the-art solvers across various time scales. For example, EARLI handles vehicle routing with 500 locations within 1s, 10x faster than current solvers for the same solution quality, enabling applications like real-time and interactive routing. EARLI can generalize to new data, as demonstrated on real e-commerce delivery data of a previously unseen city. Our hybrid framework presents a new way to combine reinforcement <span class="search-hit mathjax">learning</span> and genetic algorithms, paving the road for closer interdisciplinary collaboration between AI and optimization communities towards real-time optimization in diverse domains.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06126v1-abstract-full').style.display = 'none'; document.getElementById('2504.06126v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06125">arXiv:2504.06125</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06125">pdf</a>, <a href="https://arxiv.org/format/2504.06125">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Robo-taxi Fleet Coordination at Scale via Reinforcement <span class="search-hit mathjax">Learning</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Tresca%2C+L">Luigi Tresca</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Schmidt%2C+C">Carolin Schmidt</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Harrison%2C+J">James Harrison</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rodrigues%2C+F">Filipe Rodrigues</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zardini%2C+G">Gioele Zardini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gammelli%2C+D">Daniele Gammelli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pavone%2C+M">Marco Pavone</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06125v1-abstract-short" style="display: inline;">
        &hellip;framework that unites mathematical modeling with data-driven techniques. In particular, we present the AMoD coordination problem through the lens of reinforcement <span class="search-hit mathjax">learning</span> and propose a graph network-based framework that exploits the main strengths of graph representation&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06125v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06125v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06125v1-abstract-full" style="display: none;">
        Fleets of robo-taxis offering on-demand transportation services, commonly known as Autonomous Mobility-on-Demand (AMoD) systems, hold significant promise for societal benefits, such as reducing pollution, energy consumption, and urban congestion. However, orchestrating these systems at scale remains a critical challenge, with existing coordination algorithms often failing to exploit the systems&#39; full potential. This work introduces a novel decision-making framework that unites mathematical modeling with data-driven techniques. In particular, we present the AMoD coordination problem through the lens of reinforcement <span class="search-hit mathjax">learning</span> and propose a graph network-based framework that exploits the main strengths of graph representation <span class="search-hit mathjax">learning</span>, reinforcement <span class="search-hit mathjax">learning</span>, and classical operations research tools. Extensive evaluations across diverse simulation fidelities and scenarios demonstrate the flexibility of our approach, achieving superior system performance, computational efficiency, and generalizability compared to prior methods. Finally, motivated by the need to democratize research efforts in this area, we release publicly available benchmarks, datasets, and simulators for network-level coordination alongside an open-source codebase designed to provide accessible simulation platforms and establish a standardized validation process for comparing methodologies. Code available at: https://github.com/StanfordASL/RL4AMOD
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06125v1-abstract-full').style.display = 'none'; document.getElementById('2504.06125v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">12 pages, 6 figures, 6 tables</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06105">arXiv:2504.06105</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06105">pdf</a>, <a href="https://arxiv.org/format/2504.06105">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Uncertainty-Aware Hybrid <span class="search-hit mathjax">Machine</span> <span class="search-hit mathjax">Learning</span> in Virtual Sensors for Vehicle Sideslip Angle Estimation
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kalyanasundaram%2C+A">Abinav Kalyanasundaram</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sekaran%2C+K+C">Karthikeyan Chandra Sekaran</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Stauber%2C+P">Philipp Stauber</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lange%2C+M">Michael Lange</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Utschick%2C+W">Wolfgang Utschick</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Botsch%2C+M">Michael Botsch</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06105v1-abstract-short" style="display: inline;">
        &hellip;limitations by focusing on the development of high-performance virtual sensors to enhance vehicle state estimation for active safety. The proposed Uncertainty-Aware Hybrid <span class="search-hit mathjax">Learning</span> (UAHL) architecture integrates a&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06105v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06105v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06105v1-abstract-full" style="display: none;">
        Precise vehicle state estimation is crucial for safe and reliable autonomous driving. The number of measurable states and their precision offered by the onboard vehicle sensor system are often constrained by cost. For instance, measuring critical quantities such as the Vehicle Sideslip Angle (VSA) poses significant commercial challenges using current optical sensors. This paper addresses these limitations by focusing on the development of high-performance virtual sensors to enhance vehicle state estimation for active safety. The proposed Uncertainty-Aware Hybrid <span class="search-hit mathjax">Learning</span> (UAHL) architecture integrates a <span class="search-hit mathjax">machine</span> <span class="search-hit mathjax">learning</span> model with vehicle motion models to estimate VSA directly from onboard sensor data. A key aspect of the UAHL architecture is its focus on uncertainty quantification for individual model estimates and hybrid fusion. These mechanisms enable the dynamic weighting of uncertainty-aware predictions from <span class="search-hit mathjax">machine</span> <span class="search-hit mathjax">learning</span> and vehicle motion models to produce accurate and reliable hybrid VSA estimates. This work also presents a novel dataset named Real-world Vehicle State Estimation Dataset (ReV-StED), comprising synchronized measurements from advanced vehicle dynamic sensors. The experimental results demonstrate the superior performance of the proposed method for VSA estimation, highlighting UAHL as a promising architecture for advancing virtual sensors and enhancing active safety in autonomous vehicles.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06105v1-abstract-full').style.display = 'none'; document.getElementById('2504.06105v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted at the 2025 IEEE Intelligent Vehicles Symposium (IV)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06099">arXiv:2504.06099</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06099">pdf</a>, <a href="https://arxiv.org/format/2504.06099">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Towards Varroa destructor mite detection using a narrow spectra illumination
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Bielik%2C+S">Samuel Bielik</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bilik%2C+S">Simon Bilik</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06099v1-abstract-short" style="display: inline;">
        This paper focuses on the development and modification of a beehive monitoring device and Varroa destructor detection on the bees with the help of hyperspectral imagery while utilizing a U-net, semantic segmentation architecture, and conventional computer vision methods. The main objectives were to collect a dataset of bees and mites, and propose the computer vision model which can achieve the det&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06099v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06099v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06099v1-abstract-full" style="display: none;">
        This paper focuses on the development and modification of a beehive monitoring device and Varroa destructor detection on the bees with the help of hyperspectral imagery while utilizing a U-net, semantic segmentation architecture, and conventional computer vision methods. The main objectives were to collect a dataset of bees and mites, and propose the computer vision model which can achieve the detection between bees and mites.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06099v1-abstract-full').style.display = 'none'; document.getElementById('2504.06099v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06095">arXiv:2504.06095</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06095">pdf</a>, <a href="https://arxiv.org/format/2504.06095">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Nonuniform-Tensor-Parallelism: Mitigating GPU failure impact for Scaled-up LLM Training
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Arfeen%2C+D">Daiyaan Arfeen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mudigere%2C+D">Dheevatsa Mudigere</a>, 
      
      <a href="/search/?searchtype=author&amp;query=More%2C+A">Ankit More</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gopireddy%2C+B">Bhargava Gopireddy</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Inci%2C+A">Ahmet Inci</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ganger%2C+G+R">Gregory R. Ganger</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06095v1-abstract-short" style="display: inline;">
        LLM training is scaled up to 10Ks of GPUs by a mix of data-(DP) and model-parallel (MP) execution. Critical to achieving efficiency is tensor-parallel (TP; a form of MP) execution within tightly-coupled subsets of GPUs, referred to as a scale-up domain, and the larger the scale-up domain the better the performance. New datacenter architectures are emerging with more GPUs able to be tightly-coupled&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06095v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06095v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06095v1-abstract-full" style="display: none;">
        LLM training is scaled up to 10Ks of GPUs by a mix of data-(DP) and model-parallel (MP) execution. Critical to achieving efficiency is tensor-parallel (TP; a form of MP) execution within tightly-coupled subsets of GPUs, referred to as a scale-up domain, and the larger the scale-up domain the better the performance. New datacenter architectures are emerging with more GPUs able to be tightly-coupled in a scale-up domain, such as moving from 8 GPUs to 72 GPUs connected via NVLink. Unfortunately, larger scale-up domains increase the blast-radius of failures, with a failure of single GPU potentially impacting TP execution on the full scale-up domain, which can degrade overall LLM training throughput dramatically. With as few as 0.1% of GPUs being in a failed state, a high TP-degree job can experience nearly 10% reduction in LLM training throughput. We propose nonuniform-tensor-parallelism (NTP) to mitigate this amplified impact of GPU failures. In NTP, a DP replica that experiences GPU failures operates at a reduced TP degree, contributing throughput equal to the percentage of still-functional GPUs. We also propose a rack-design with improved electrical and thermal capabilities in order to sustain power-boosting of scale-up domains that have experienced failures; combined with NTP, this can allow the DP replica with the reduced TP degree (i.e., with failed GPUs) to keep up with the others, thereby achieving near-zero throughput loss for large-scale LLM training.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06095v1-abstract-full').style.display = 'none'; document.getElementById('2504.06095v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06088">arXiv:2504.06088</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06088">pdf</a>, <a href="https://arxiv.org/format/2504.06088">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        MCAT: Visual Query-Based Localization of Standard Anatomical Clips in Fetal Ultrasound Videos Using Multi-Tier Class-Aware Token Transformer
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Mishra%2C+D">Divyanshu Mishra</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Saha%2C+P">Pramit Saha</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhao%2C+H">He Zhao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hernandez-Cruz%2C+N">Netzahualcoyotl Hernandez-Cruz</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Patey%2C+O">Olga Patey</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Papageorghiou%2C+A">Aris Papageorghiou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Noble%2C+J+A">J. Alison Noble</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06088v1-abstract-short" style="display: inline;">
        Accurate standard plane acquisition in fetal ultrasound (US) videos is crucial for fetal growth assessment, anomaly detection, and adherence to clinical guidelines. However, manually selecting standard frames is time-consuming and prone to intra- and inter-sonographer variability. Existing methods primarily rely on image-based approaches that capture standard frames and then classify the input fra&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06088v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06088v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06088v1-abstract-full" style="display: none;">
        Accurate standard plane acquisition in fetal ultrasound (US) videos is crucial for fetal growth assessment, anomaly detection, and adherence to clinical guidelines. However, manually selecting standard frames is time-consuming and prone to intra- and inter-sonographer variability. Existing methods primarily rely on image-based approaches that capture standard frames and then classify the input frames across different anatomies. This ignores the dynamic nature of video acquisition and its interpretation. To address these challenges, we introduce Multi-Tier Class-Aware Token Transformer (MCAT), a visual query-based video clip localization (VQ-VCL) method, to assist sonographers by enabling them to capture a quick US sweep. By then providing a visual query of the anatomy they wish to analyze, MCAT returns the video clip containing the standard frames for that anatomy, facilitating thorough screening for potential anomalies. We evaluate MCAT on two ultrasound video datasets and a natural image VQ-VCL dataset based on Ego4D. Our model outperforms state-of-the-art methods by 10% and 13% mIoU on the ultrasound datasets and by 5.35% mIoU on the Ego4D dataset, using 96% fewer tokens. MCAT&#39;s efficiency and accuracy have significant potential implications for public health, especially in low- and middle-income countries (LMICs), where it may enhance prenatal care by streamlining standard plane acquisition, simplifying US-based screening, diagnosis and allowing sonographers to examine more patients.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06088v1-abstract-full').style.display = 'none'; document.getElementById('2504.06088v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted in AAAI 2025</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06087">arXiv:2504.06087</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06087">pdf</a>, <a href="https://arxiv.org/format/2504.06087">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computational Physics">physics.comp-ph</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Chemical Physics">physics.chem-ph</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Accurate Ab-initio Neural-network Solutions to Large-Scale Electronic Structure Problems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Scherbela%2C+M">Michael Scherbela</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gao%2C+N">Nicholas Gao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Grohs%2C+P">Philipp Grohs</a>, 
      
      <a href="/search/?searchtype=author&amp;query=G%C3%BCnnemann%2C+S">Stephan Günnemann</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06087v1-abstract-short" style="display: inline;">
        We present finite-range embeddings (FiRE), a novel wave function ansatz for accurate large-scale ab-initio electronic structure calculations. Compared to contemporary neural-network wave functions, FiRE reduces the asymptotic complexity of neural-network variational Monte Carlo (NN-VMC) by $\sim n_\text{el}$, the number of electrons. By restricting electron-electron interactions within the neural&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06087v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06087v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06087v1-abstract-full" style="display: none;">
        We present finite-range embeddings (FiRE), a novel wave function ansatz for accurate large-scale ab-initio electronic structure calculations. Compared to contemporary neural-network wave functions, FiRE reduces the asymptotic complexity of neural-network variational Monte Carlo (NN-VMC) by $\sim n_\text{el}$, the number of electrons. By restricting electron-electron interactions within the neural network, FiRE accelerates all key operations -- sampling, pseudopotentials, and Laplacian computations -- resulting in a real-world $10\times$ acceleration in now-feasible 180-electron calculations. We validate our method&#39;s accuracy on various challenging systems, including biochemical compounds, conjugated hydrocarbons, and organometallic compounds. On these systems, FiRE&#39;s energies are consistently within chemical accuracy of the most reliable data, including experiments, even in cases where high-accuracy methods such as CCSD(T), AFQMC, or contemporary NN-VMC fall short. With these improvements in both runtime and accuracy, FiRE represents a new `gold-standard&#39; method for fast and accurate large-scale ab-initio calculations, potentially enabling new computational studies in fields like quantum chemistry, solid-state physics, and material design.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06087v1-abstract-full').style.display = 'none'; document.getElementById('2504.06087v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">13 pages, 5 figures + 9 pages supplementary information</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06075">arXiv:2504.06075</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06075">pdf</a>, <a href="https://arxiv.org/ps/2504.06075">ps</a>, <a href="https://arxiv.org/format/2504.06075">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Science and Game Theory">cs.GT</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Collaborative Prediction: Tractable Information Aggregation via Agreement
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Collina%2C+N">Natalie Collina</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Globus-Harris%2C+I">Ira Globus-Harris</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Goel%2C+S">Surbhi Goel</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gupta%2C+V">Varun Gupta</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Roth%2C+A">Aaron Roth</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shi%2C+M">Mirah Shi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06075v1-abstract-short" style="display: inline;">
        &hellip;update their own label predictions-without either party ever having to share the actual features that they observe. Our protocols are efficient reductions to the problem of <span class="search-hit mathjax">learning</span> on each party&#39;s feature space alone, and so can be used even in settings in which each party&#39;s feature space is illegible to the other-which arises in models of human/AI&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06075v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06075v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06075v1-abstract-full" style="display: none;">
        We give efficient &#34;collaboration protocols&#34; through which two parties, who observe different features about the same instances, can interact to arrive at predictions that are more accurate than either could have obtained on their own. The parties only need to iteratively share and update their own label predictions-without either party ever having to share the actual features that they observe. Our protocols are efficient reductions to the problem of <span class="search-hit mathjax">learning</span> on each party&#39;s feature space alone, and so can be used even in settings in which each party&#39;s feature space is illegible to the other-which arises in models of human/AI interaction and in multi-modal <span class="search-hit mathjax">learning</span>. The communication requirements of our protocols are independent of the dimensionality of the data. In an online adversarial setting we show how to give regret bounds on the predictions that the parties arrive at with respect to a class of benchmark policies defined on the joint feature space of the two parties, despite the fact that neither party has access to this joint feature space. We also give simpler algorithms for the same task in the batch setting in which we assume that there is a fixed but unknown data distribution. We generalize our protocols to a decision theoretic setting with high dimensional outcome spaces, where parties communicate only &#34;best response actions.&#34;
  Our theorems give a computationally and statistically tractable generalization of past work on information aggregation amongst Bayesians who share a common and correct prior, as part of a literature studying &#34;agreement&#34; in the style of Aumann&#39;s agreement theorem. Our results require no knowledge of (or even the existence of) a prior distribution and are computationally efficient. Nevertheless we show how to lift our theorems back to this classical Bayesian setting, and in doing so, give new information aggregation theorems for Bayesian agreement.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06075v1-abstract-full').style.display = 'none'; document.getElementById('2504.06075v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06070">arXiv:2504.06070</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06070">pdf</a>, <a href="https://arxiv.org/format/2504.06070">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        PINP: Physics-Informed Neural Predictor with latent estimation of fluid flows
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+H">Huaguan Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Y">Yang Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sun%2C+H">Hao Sun</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06070v1-abstract-short" style="display: inline;">
        Accurately predicting fluid dynamics and evolution has been a long-standing challenge in physical sciences. Conventional deep <span class="search-hit mathjax">learning</span> methods often rely on the nonlinear modeling capabilities of neural networks to establish mappings between past and future states, overlooking the fluid dynamics, or only modeling the velocity field, neglecting the coupling o&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06070v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06070v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06070v1-abstract-full" style="display: none;">
        Accurately predicting fluid dynamics and evolution has been a long-standing challenge in physical sciences. Conventional deep <span class="search-hit mathjax">learning</span> methods often rely on the nonlinear modeling capabilities of neural networks to establish mappings between past and future states, overlooking the fluid dynamics, or only modeling the velocity field, neglecting the coupling of multiple physical quantities. In this paper, we propose a new physics-informed <span class="search-hit mathjax">learning</span> approach that incorporates coupled physical quantities into the prediction process to assist with forecasting. Central to our method lies in the discretization of physical equations, which are directly integrated into the model architecture and loss function. This integration enables the model to provide robust, long-term future predictions. By incorporating physical equations, our model demonstrates temporal extrapolation and spatial generalization capabilities. Experimental results show that our approach achieves the state-of-the-art performance in spatiotemporal prediction across both numerical simulations and real-world extreme-precipitation nowcasting benchmarks.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06070v1-abstract-full').style.display = 'none'; document.getElementById('2504.06070v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06055">arXiv:2504.06055</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06055">pdf</a>, <a href="https://arxiv.org/format/2504.06055">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Explainable AI for building energy retrofitting under data scarcity
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Rempi%2C+P">Panagiota Rempi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pelekis%2C+S">Sotiris Pelekis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tzortzis%2C+A+M">Alexandros Menelaos Tzortzis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Karakolis%2C+E">Evangelos Karakolis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ntanos%2C+C">Christos Ntanos</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Askounis%2C+D">Dimitris Askounis</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06055v1-abstract-short" style="display: inline;">
        &hellip;portion of energy consumption, is critical particularly in regions with outdated and inefficient building stocks. This study presents an Artificial Intelligence (AI) and <span class="search-hit mathjax">Machine</span> <span class="search-hit mathjax">Learning</span> (ML)-based framework to recommend energy efficiency measures for residential buildings, leveraging accessible building characteristic&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06055v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06055v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06055v1-abstract-full" style="display: none;">
        Enhancing energy efficiency in residential buildings is a crucial step toward mitigating climate change and reducing greenhouse gas emissions. Retrofitting existing buildings, which account for a significant portion of energy consumption, is critical particularly in regions with outdated and inefficient building stocks. This study presents an Artificial Intelligence (AI) and <span class="search-hit mathjax">Machine</span> <span class="search-hit mathjax">Learning</span> (ML)-based framework to recommend energy efficiency measures for residential buildings, leveraging accessible building characteristics to achieve energy class targets. Using Latvia as a case study, the methodology addresses challenges associated with limited datasets, class imbalance and data scarcity. The proposed approach integrates Conditional Tabular Generative Adversarial Networks (CTGAN) to generate synthetic data, enriching and balancing the dataset. A Multi-Layer Perceptron (MLP) model serves as the predictive model performing multi-label classification to predict appropriate retrofit strategies. Explainable Artificial Intelligence (XAI), specifically SHapley Additive exPlanations (SHAP), ensures transparency and trust by identifying key features that influence recommendations and guiding feature engineering choices for improved reliability and performance. The evaluation of the approach shows that it notably overcomes data limitations, achieving improvements up to 54% in precision, recall and F1 score. Although this study focuses on Latvia, the methodology is adaptable to other regions, underscoring the potential of AI in reducing the complexity and cost of building energy retrofitting overcoming data limitations. By facilitating decision-making processes and promoting stakeholders engagement, this work supports the global transition toward sustainable energy use in the residential building sector.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06055v1-abstract-full').style.display = 'none'; document.getElementById('2504.06055v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06048">arXiv:2504.06048</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06048">pdf</a>, <a href="https://arxiv.org/format/2504.06048">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Trust-Region Twisted Policy Improvement
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=de+Vries%2C+J+A">Joery A. de Vries</a>, 
      
      <a href="/search/?searchtype=author&amp;query=He%2C+J">Jinke He</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Oren%2C+Y">Yaniv Oren</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Spaan%2C+M+T+J">Matthijs T. J. Spaan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06048v1-abstract-short" style="display: inline;">
        Monte-Carlo tree search (MCTS) has driven many recent breakthroughs in deep reinforcement <span class="search-hit mathjax">learning</span> (RL). However, scaling MCTS to parallel compute has proven challenging in practice which has motivated alternative planners like sequential Monte-Carlo (SMC). Many of these SMC methods adopt particle filters for smoothing through a reformulation of RL as a poli&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06048v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06048v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06048v1-abstract-full" style="display: none;">
        Monte-Carlo tree search (MCTS) has driven many recent breakthroughs in deep reinforcement <span class="search-hit mathjax">learning</span> (RL). However, scaling MCTS to parallel compute has proven challenging in practice which has motivated alternative planners like sequential Monte-Carlo (SMC). Many of these SMC methods adopt particle filters for smoothing through a reformulation of RL as a policy inference problem. Yet, persisting design choices of these particle filters often conflict with the aim of online planning in RL, which is to obtain a policy improvement at the start of planning. Drawing inspiration from MCTS, we tailor SMC planners specifically for RL by improving data generation within the planner through constrained action sampling and explicit terminal state handling, as well as improving policy and value target estimation. This leads to our Trust-Region Twisted SMC (TRT-SMC), which shows improved runtime and sample-efficiency over baseline MCTS and SMC methods in both discrete and continuous domains.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06048v1-abstract-full').style.display = 'none'; document.getElementById('2504.06048v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06039">arXiv:2504.06039</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06039">pdf</a>, <a href="https://arxiv.org/format/2504.06039">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Enhanced Anomaly Detection for Capsule Endoscopy Using Ensemble <span class="search-hit mathjax">Learning</span> Strategies
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Werner%2C+J">Julia Werner</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gerum%2C+C">Christoph Gerum</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nick%2C+J">Jorg Nick</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Floch%2C+M+L">Maxime Le Floch</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Brinkmann%2C+F">Franz Brinkmann</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hampe%2C+J">Jochen Hampe</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bringmann%2C+O">Oliver Bringmann</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06039v1-abstract-short" style="display: inline;">
        &hellip;in anomaly detection tasks in video capsule endoscopies, requiring only a small number of individual neural networks during both the training and inference phases. Ensemble <span class="search-hit mathjax">learning</span> combines the predictions of multiple independently trained neural networks. This has shown to be highly effective in enhancing both the accuracy and robustness of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06039v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06039v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06039v1-abstract-full" style="display: none;">
        Capsule endoscopy is a method to capture images of the gastrointestinal tract and screen for diseases which might remain hidden if investigated with standard endoscopes. Due to the limited size of a video capsule, embedding AI models directly into the capsule demands careful consideration of the model size and thus complicates anomaly detection in this field. Furthermore, the scarcity of available data in this domain poses an ongoing challenge to achieving effective anomaly detection. Thus, this work introduces an ensemble strategy to address this challenge in anomaly detection tasks in video capsule endoscopies, requiring only a small number of individual neural networks during both the training and inference phases. Ensemble <span class="search-hit mathjax">learning</span> combines the predictions of multiple independently trained neural networks. This has shown to be highly effective in enhancing both the accuracy and robustness of <span class="search-hit mathjax">machine</span> <span class="search-hit mathjax">learning</span> models. However, this comes at the cost of higher memory usage and increased computational effort, which quickly becomes prohibitive in many real-world applications. Instead of applying the same training algorithm to each individual network, we propose using various loss functions, drawn from the anomaly detection field, to train each network. The methods are validated on the two largest publicly available datasets for video capsule endoscopy images, the Galar and the Kvasir-Capsule dataset. We achieve an AUC score of 76.86% on the Kvasir-Capsule and an AUC score of 76.98% on the Galar dataset. Our approach outperforms current baselines with significantly fewer parameters across all models, which is a crucial step towards incorporating artificial intelligence into capsule endoscopies.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06039v1-abstract-full').style.display = 'none'; document.getElementById('2504.06039v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted at the 47th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBS EMBC)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06037">arXiv:2504.06037</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06037">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Confidence Regularized Masked Language Modeling using Text Length
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ji%2C+S">Seunghyun Ji</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lee%2C+S">Soowon Lee</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06037v1-abstract-short" style="display: inline;">
        Masked language modeling, which is a task to predict a randomly masked word in the input text, is an efficient language representation <span class="search-hit mathjax">learning</span> method. Masked language modeling ignores various words which people can think of for filling in the masked position and calculates the loss with a single word. Especially when the input text is short, the entropy of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06037v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06037v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06037v1-abstract-full" style="display: none;">
        Masked language modeling, which is a task to predict a randomly masked word in the input text, is an efficient language representation <span class="search-hit mathjax">learning</span> method. Masked language modeling ignores various words which people can think of for filling in the masked position and calculates the loss with a single word. Especially when the input text is short, the entropy of the word distribution that can fill in the masked position can be high. This may cause the model to be overconfident in the single answer. To address this issue, we propose a novel confidence regularizer that controls regularizing strength dynamically by the input text length. Experiments with GLUE and SQuAD datasets showed that our method achieves better accuracy and lower expected calibration error.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06037v1-abstract-full').style.display = 'none'; document.getElementById('2504.06037v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">10 pages, 1 figure</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06015">arXiv:2504.06015</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06015">pdf</a>, <a href="https://arxiv.org/ps/2504.06015">ps</a>, <a href="https://arxiv.org/format/2504.06015">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Robust Statistics vs. <span class="search-hit mathjax">Machine</span> <span class="search-hit mathjax">Learning</span> vs. Bayesian Inference: Insights into Handling Faulty GNSS Measurements in Field Robotics
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+H">Haoming Zhang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06015v1-abstract-short" style="display: inline;">
        &hellip;non-line-of-sight conditions. In this context, we investigate three strategies applied specifically to GNSS pseudorange observations: robust statistics for error mitigation, <span class="search-hit mathjax">machine</span> <span class="search-hit mathjax">learning</span> for faulty measurement prediction, and Bayesian inference for noise distribution approximation. Since previous studies have provi&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06015v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06015v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06015v1-abstract-full" style="display: none;">
        This paper presents research findings on handling faulty measurements (i.e., outliers) of global navigation satellite systems (GNSS) for robot localization under adverse signal conditions in field applications, where raw GNSS data are frequently corrupted due to environmental interference such as multipath, signal blockage, or non-line-of-sight conditions. In this context, we investigate three strategies applied specifically to GNSS pseudorange observations: robust statistics for error mitigation, <span class="search-hit mathjax">machine</span> <span class="search-hit mathjax">learning</span> for faulty measurement prediction, and Bayesian inference for noise distribution approximation. Since previous studies have provided limited insight into the theoretical foundations and practical evaluations of these three methodologies within a unified problem statement (i.e., state estimation using ranging sensors), we conduct extensive experiments using real-world sensor data collected in diverse urban environments. Our goal is to examine both established techniques and newly proposed methods, thereby advancing the understanding of how to handle faulty range measurements, such as GNSS, for robust, long-term robot localization. In addition to presenting successful results, this work highlights critical observations and open questions to motivate future research in robust state estimation.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06015v1-abstract-full').style.display = 'none'; document.getElementById('2504.06015v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06012">arXiv:2504.06012</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06012">pdf</a>, <a href="https://arxiv.org/format/2504.06012">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Econometrics">econ.EM</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Applications">stat.AP</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Optimizing Data-driven Weights In Multidimensional Indexes
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ceriani%2C+L">Lidia Ceriani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gigliarano%2C+C">Chiara Gigliarano</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Verme%2C+P">Paolo Verme</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06012v1-abstract-short" style="display: inline;">
        &hellip;of weights by defining a set of desirable properties that weighting models should meet. It shows that Bayesian Networks is the only model across statistical, econometric, and <span class="search-hit mathjax">machine</span> <span class="search-hit mathjax">learning</span> computational models that meets these properties. An example with EU-SILC data illustrates this new approach highlighting its po&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06012v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06012v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06012v1-abstract-full" style="display: none;">
        Multidimensional indexes are ubiquitous, and popular, but present non-negligible normative choices when it comes to attributing weights to their dimensions. This paper provides a more rigorous approach to the choice of weights by defining a set of desirable properties that weighting models should meet. It shows that Bayesian Networks is the only model across statistical, econometric, and <span class="search-hit mathjax">machine</span> <span class="search-hit mathjax">learning</span> computational models that meets these properties. An example with EU-SILC data illustrates this new approach highlighting its potential for policies.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06012v1-abstract-full').style.display = 'none'; document.getElementById('2504.06012v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">18 pages, 3 Figures, 3 Tables</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06007">arXiv:2504.06007</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06007">pdf</a>, <a href="https://arxiv.org/format/2504.06007">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Atmospheric and Oceanic Physics">physics.ao-ph</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        CAMulator: Fast Emulation of the Community Atmosphere Model
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Chapman%2C+W+E">William E. Chapman</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Schreck%2C+J+S">John S. Schreck</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sha%2C+Y">Yingkai Sha</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gagne%2C+D+J">David John Gagne II</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kimpara%2C+D">Dhamma Kimpara</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zanna%2C+L">Laure Zanna</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mayer%2C+K+J">Kirsten J. Mayer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Berner%2C+J">Judith Berner</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06007v1-abstract-short" style="display: inline;">
        We introduce CAMulator version 1, an auto-regressive <span class="search-hit mathjax">machine</span>-<span class="search-hit mathjax">learned</span> (ML) emulator of the Community Atmosphere Model version 6 (CAM6) that simulates the next atmospheric state given the prescribed sea surface temperatures and incoming solar radiation. CAMulator explicitly conserves global dry air mass, moisture, and to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06007v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06007v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06007v1-abstract-full" style="display: none;">
        We introduce CAMulator version 1, an auto-regressive <span class="search-hit mathjax">machine</span>-<span class="search-hit mathjax">learned</span> (ML) emulator of the Community Atmosphere Model version 6 (CAM6) that simulates the next atmospheric state given the prescribed sea surface temperatures and incoming solar radiation. CAMulator explicitly conserves global dry air mass, moisture, and total atmospheric energy while remaining numerically stable over indefinite climate integrations. It successfully reproduces the annual CAM6 climatology and key modes of climate variability, including the El Niño-Southern Oscillation, the North Atlantic Oscillation, and the Pacific-North American pattern, with slightly muted variability. When forced with sea surface temperature (SST) outside the training distribution, CAMulator exhibits a systematic cold bias in high-latitude regions, particularly in boreal winter, likely due to the absence of interactive land and sea ice. Nonetheless, CAMulator achieves these results with a 350 times speedup over CAM6, making it an efficient alternative for generating large ensembles.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06007v1-abstract-full').style.display = 'none'; document.getElementById('2504.06007v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.06006">arXiv:2504.06006</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.06006">pdf</a>, <a href="https://arxiv.org/format/2504.06006">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Optuna vs Code Llama: Are LLMs a New Paradigm for Hyperparameter Tuning?
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kochnev%2C+R">Roman Kochnev</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Goodarzi%2C+A+T">Arash Torabi Goodarzi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bentyn%2C+Z+A">Zofia Antonina Bentyn</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ignatov%2C+D">Dmitry Ignatov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Timofte%2C+R">Radu Timofte</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.06006v1-abstract-short" style="display: inline;">
        &hellip;efficiency is paramount. The results confirm that LLMs, beyond their efficiency, offer substantial time savings and comparable stability, underscoring their value in advancing <span class="search-hit mathjax">machine</span> <span class="search-hit mathjax">learning</span> workflows. All generated hyperparameters are included in the LEMUR Neural Network (NN) Dataset, which is publicly available and&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06006v1-abstract-full').style.display = 'inline'; document.getElementById('2504.06006v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.06006v1-abstract-full" style="display: none;">
        Optimal hyperparameter selection is critical for maximizing neural network performance, especially as models grow in complexity. This work investigates the viability of using large language models (LLMs) for hyperparameter optimization by employing a fine-tuned version of Code Llama. Through parameter-efficient fine-tuning using LoRA, we adapt the LLM to generate accurate and efficient hyperparameter recommendations tailored to diverse neural network architectures. Unlike traditional methods such as Optuna, which rely on exhaustive trials, the proposed approach achieves competitive or superior results in terms of Root Mean Square Error (RMSE) while significantly reducing computational overhead. Our approach highlights that LLM-based optimization not only matches state-of-the-art methods like Tree-structured Parzen Estimators but also accelerates the tuning process. This positions LLMs as a promising alternative to conventional optimization techniques, particularly for rapid experimentation. Furthermore, the ability to generate hyperparameters in a single inference step makes this method particularly well-suited for resource-constrained environments such as edge devices and mobile applications, where computational efficiency is paramount. The results confirm that LLMs, beyond their efficiency, offer substantial time savings and comparable stability, underscoring their value in advancing <span class="search-hit mathjax">machine</span> <span class="search-hit mathjax">learning</span> workflows. All generated hyperparameters are included in the LEMUR Neural Network (NN) Dataset, which is publicly available and serves as an open-source benchmark for hyperparameter optimization research.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.06006v1-abstract-full').style.display = 'none'; document.getElementById('2504.06006v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.05987">arXiv:2504.05987</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.05987">pdf</a>, <a href="https://arxiv.org/format/2504.05987">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1109/TIM.2025.3546404">10.1109/TIM.2025.3546404 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Learning</span>-enhanced electronic skin for tactile sensing on deformable surface based on electrical impedance tomography
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Dong%2C+H">Huazhi Dong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+X">Xiaopeng Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hu%2C+D">Delin Hu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Z">Zhe Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Giorgio-Serchi%2C+F">Francesco Giorgio-Serchi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+Y">Yunjie Yang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.05987v1-abstract-short" style="display: inline;">
        &hellip;to disentangle the parameter being measured and the signal deriving from shape changes. This has largely limited their practical implementations. This paper presents a <span class="search-hit mathjax">machine</span>&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.05987v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05987v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.05987v1-abstract-full" style="display: none;">
        Electrical Impedance Tomography (EIT)-based tactile sensors offer cost-effective and scalable solutions for robotic sensing, especially promising for soft robots. However a major issue of EIT-based tactile sensors when applied in highly deformable objects is their performance degradation due to surface deformations. This limitation stems from their inherent sensitivity to strain, which is particularly exacerbated in soft bodies, thus requiring dedicated data interpretation to disentangle the parameter being measured and the signal deriving from shape changes. This has largely limited their practical implementations. This paper presents a <span class="search-hit mathjax">machine</span> <span class="search-hit mathjax">learning</span>-assisted tactile sensing approach to address this challenge by tracking surface deformations and segregating this contribution in the signal readout during tactile sensing. We first capture the deformations of the target object, followed by tactile reconstruction using a deep <span class="search-hit mathjax">learning</span> model specifically designed to process and fuse EIT data and deformation information. Validations using numerical simulations achieved high correlation coefficients (0.9660 - 0.9999), peak signal-to-noise ratios (28.7221 - 55.5264 dB) and low relative image errors (0.0107 - 0.0805). Experimental validations, using a hydrogel-based EIT e-skin under various deformation scenarios, further demonstrated the effectiveness of the proposed approach in real-world settings. The findings could underpin enhanced tactile interaction in soft and highly deformable robotic applications.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.05987v1-abstract-full').style.display = 'none'; document.getElementById('2504.05987v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        IEEE Transactions on Instrumentation and Measurement, vol. 74, pp. 1-9, 2025, Art no. 4503109
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.05978">arXiv:2504.05978</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.05978">pdf</a>, <a href="https://arxiv.org/format/2504.05978">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Smart Exploration in Reinforcement <span class="search-hit mathjax">Learning</span> using Bounded Uncertainty Models
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=van+Hulst%2C+J+S">J. S. van Hulst</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Heemels%2C+W+P+M+H">W. P. M. H. Heemels</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Antunes%2C+D+J">D. J. Antunes</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.05978v1-abstract-short" style="display: inline;">
        Reinforcement <span class="search-hit mathjax">learning</span> (RL) is a powerful tool for decision-making in uncertain environments, but it often requires large amounts of data to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.05978v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05978v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.05978v1-abstract-full" style="display: none;">
        Reinforcement <span class="search-hit mathjax">learning</span> (RL) is a powerful tool for decision-making in uncertain environments, but it often requires large amounts of data to <span class="search-hit mathjax">learn</span> an optimal policy. We propose using prior model knowledge to guide the exploration process to speed up this <span class="search-hit mathjax">learning</span> process. This model knowledge comes in the form of a model set to which the true transition kernel and reward function belong. We optimize over this model set to obtain upper and lower bounds on the Q-function, which are then used to guide the exploration of the agent. We provide theoretical guarantees on the convergence of the Q-function to the optimal Q-function under the proposed class of exploring policies. Furthermore, we also introduce a data-driven regularized version of the model set optimization problem that ensures the convergence of the class of exploring policies to the optimal policy. Lastly, we show that when the model set has a specific structure, namely the bounded-parameter MDP (BMDP) framework, the regularized model set optimization problem becomes convex and simple to implement. In this setting, we also show that we obtain finite-time convergence to the optimal policy under additional assumptions. We demonstrate the effectiveness of the proposed exploration strategy in a simulation study. The results indicate that the proposed method can significantly speed up the <span class="search-hit mathjax">learning</span> process in reinforcement <span class="search-hit mathjax">learning</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.05978v1-abstract-full').style.display = 'none'; document.getElementById('2504.05978v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Submitted for publication</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.05970">arXiv:2504.05970</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.05970">pdf</a>, <a href="https://arxiv.org/format/2504.05970">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computational Engineering, Finance, and Science">cs.CE</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        MLPROP -- an open interactive web interface for thermophysical property prediction with <span class="search-hit mathjax">machine</span> <span class="search-hit mathjax">learning</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Hoffmann%2C+M">Marco Hoffmann</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Specht%2C+T">Thomas Specht</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hayer%2C+N">Nicolas Hayer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hasse%2C+H">Hans Hasse</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jirasek%2C+F">Fabian Jirasek</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.05970v1-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">Machine</span>&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.05970v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05970v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.05970v1-abstract-full" style="display: none;">
        <span class="search-hit mathjax">Machine</span> <span class="search-hit mathjax">learning</span> (ML) enables the development of powerful methods for predicting thermophysical properties with unprecedented scope and accuracy. However, technical barriers like cumbersome implementation in established workflows hinder their application in practice. With MLPROP, we provide an interactive web interface for directly applying advanced ML methods to predict thermophysical properties without requiring ML expertise, thereby substantially increasing the accessibility of novel models. MLPROP currently includes models for predicting the vapor pressure of pure components (GRAPPA), activity coefficients and vapor-liquid equilibria in binary mixtures (UNIFAC 2.0, mod. UNIFAC 2.0, and HANNA), and a routine to fit NRTL parameters to the model predictions. MLPROP will be continuously updated and extended and is accessible free of charge via https://ml-prop.mv.rptu.de/. MLPROP removes the barrier to <span class="search-hit mathjax">learning</span> and experimenting with new ML-based methods for predicting thermophysical properties. The source code of all models is available as open source, which allows integration into existing workflows.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.05970v1-abstract-full').style.display = 'none'; document.getElementById('2504.05970v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">6 pages, 2 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.05962">arXiv:2504.05962</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.05962">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Instrumentation and Methods for Astrophysics">astro-ph.IM</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Solar and Stellar Astrophysics">astro-ph.SR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Autoencoder-Based Detection of Anomalous Stokes V Spectra in the Flare-Producing Active Region 13663 Using Hinode/SP Observations
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Batmunkh%2C+J">Jargalmaa Batmunkh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Iida%2C+Y">Yusuke Iida</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Oba%2C+T">Takayoshi Oba</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.05962v1-abstract-short" style="display: inline;">
        &hellip;when relying on pre-defined, physics-based calculations to process large volumes of noisy and complex observational data. To address these limitations, we applied deep <span class="search-hit mathjax">learning</span> to detect anomalies in the Stokes V spectra from the Hinode/SP instrument. Specifically, we developed an autoencoder model for spectral compression, which serves as an anomaly detecti&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.05962v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05962v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.05962v1-abstract-full" style="display: none;">
        Detecting unusual signals in observational solar spectra is crucial for understanding the features associated with impactful solar events, such as solar flares. However, existing spectral analysis techniques face challenges, particularly when relying on pre-defined, physics-based calculations to process large volumes of noisy and complex observational data. To address these limitations, we applied deep <span class="search-hit mathjax">learning</span> to detect anomalies in the Stokes V spectra from the Hinode/SP instrument. Specifically, we developed an autoencoder model for spectral compression, which serves as an anomaly detection method. Our model effectively identifies anomalous spectra within spectro-polarimetric maps captured prior to the onset of the X1.3 flare on May 5, 2024, in NOAA AR 13663. These atypical spectral points exhibit highly complex profiles and spatially align with polarity inversion lines in magnetogram images, indicating their potential as sites of magnetic energy storage and possible triggers for flares. Notably, the detected anomalies are highly localized, making them particularly challenging to identify in magnetogram images using current manual methods.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.05962v1-abstract-full').style.display = 'none'; document.getElementById('2504.05962v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.05957">arXiv:2504.05957</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.05957">pdf</a>, <a href="https://arxiv.org/format/2504.05957">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Drought forecasting using a hybrid neural architecture for integrating time series and static data
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Agudelo%2C+J">Julian Agudelo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Guigue%2C+V">Vincent Guigue</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Manfredotti%2C+C">Cristina Manfredotti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Piot%2C+H">Hadrien Piot</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.05957v1-abstract-short" style="display: inline;">
        Reliable forecasting is critical for early warning systems and adaptive drought management. Most previous deep <span class="search-hit mathjax">learning</span> approaches focus solely on homogeneous regions and rely on single-structured data. This paper presents a hybrid neural architecture that integrates time series and static data, achieving state-of-the-art performance on the DroughtED dataset&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.05957v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05957v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.05957v1-abstract-full" style="display: none;">
        Reliable forecasting is critical for early warning systems and adaptive drought management. Most previous deep <span class="search-hit mathjax">learning</span> approaches focus solely on homogeneous regions and rely on single-structured data. This paper presents a hybrid neural architecture that integrates time series and static data, achieving state-of-the-art performance on the DroughtED dataset. Our results illustrate the potential of designing neural models for the treatment of heterogeneous data in climate related tasks and present reliable prediction of USDM categories, an expert-informed drought metric. Furthermore, this work validates the potential of DroughtED for enabling location-agnostic training of deep <span class="search-hit mathjax">learning</span> models.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.05957v1-abstract-full').style.display = 'none'; document.getElementById('2504.05957v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">10 pages, 3 figures, published as a workshop paper at Tackling Climate Change with <span class="search-hit mathjax">Machine</span> <span class="search-hit mathjax">Learning</span> at ICLR 2025, Tackling Climate Change with <span class="search-hit mathjax">Machine</span> <span class="search-hit mathjax">Learning</span> is a non-archival workshop</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.05954">arXiv:2504.05954</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.05954">pdf</a>, <a href="https://arxiv.org/format/2504.05954">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Unsupervised Location Mapping for Narrative Corpora
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wagner%2C+E">Eitan Wagner</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Keydar%2C+R">Renana Keydar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Abend%2C+O">Omri Abend</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.05954v1-abstract-short" style="display: inline;">
        This work presents the task of unsupervised location mapping, which seeks to map the trajectory of an individual narrative on a spatial map of locations in which a large set of narratives take place. Despite the fundamentality and generality of the task, very little work addressed the spatial mapping of narrative texts. The task consists of two parts: (1) inducing a ``map&#39;&#39; with the locations ment&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.05954v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05954v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.05954v1-abstract-full" style="display: none;">
        This work presents the task of unsupervised location mapping, which seeks to map the trajectory of an individual narrative on a spatial map of locations in which a large set of narratives take place. Despite the fundamentality and generality of the task, very little work addressed the spatial mapping of narrative texts. The task consists of two parts: (1) inducing a ``map&#39;&#39; with the locations mentioned in a set of texts, and (2) extracting a trajectory from a single narrative and positioning it on the map. Following recent advances in increasing the context length of large language models, we propose a pipeline for this task in a completely unsupervised manner without predefining the set of labels. We test our method on two different domains: (1) Holocaust testimonies and (2) Lake District writing, namely multi-century literature on travels in the English Lake District. We perform both intrinsic and extrinsic evaluations for the task, with encouraging results, thereby setting a benchmark and evaluation practices for the task, as well as highlighting challenges.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.05954v1-abstract-full').style.display = 'none'; document.getElementById('2504.05954v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.05950">arXiv:2504.05950</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.05950">pdf</a>, <a href="https://arxiv.org/format/2504.05950">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        AEGIS: Human Attention-based Explainable Guidance for Intelligent Vehicle Systems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhuang%2C+Z">Zhuoli Zhuang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lu%2C+C">Cheng-You Lu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chang%2C+Y+F">Yu-Cheng Fred Chang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Y">Yu-Kai Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Do%2C+T">Thomas Do</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lin%2C+C">Chin-Teng Lin</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.05950v1-abstract-short" style="display: inline;">
        Improving decision-making capabilities in Autonomous Intelligent Vehicles (AIVs) has been a heated topic in recent years. Despite advancements, training <span class="search-hit mathjax">machines</span> to capture regions of interest for comprehensive scene understanding, like human perception and reasoning, remains a significant challenge. This study introduces a novel framework, Human Attention-b&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.05950v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05950v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.05950v1-abstract-full" style="display: none;">
        Improving decision-making capabilities in Autonomous Intelligent Vehicles (AIVs) has been a heated topic in recent years. Despite advancements, training <span class="search-hit mathjax">machines</span> to capture regions of interest for comprehensive scene understanding, like human perception and reasoning, remains a significant challenge. This study introduces a novel framework, Human Attention-based Explainable Guidance for Intelligent Vehicle Systems (AEGIS). AEGIS utilizes human attention, converted from eye-tracking, to guide reinforcement <span class="search-hit mathjax">learning</span> (RL) models to identify critical regions of interest for decision-making. AEGIS uses a pre-trained human attention model to guide RL models to identify critical regions of interest for decision-making. By collecting 1.2 million frames from 20 participants across six scenarios, AEGIS pre-trains a model to predict human attention patterns.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.05950v1-abstract-full').style.display = 'none'; document.getElementById('2504.05950v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.05945">arXiv:2504.05945</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.05945">pdf</a>, <a href="https://arxiv.org/format/2504.05945">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        CKGAN: Training Generative Adversarial Networks Using Characteristic Kernel Integral Probability Metrics
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+K">Kuntian Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yu%2C+S">Simin Yu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Y">Yaoshu Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Onizuka%2C+M">Makoto Onizuka</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xiao%2C+C">Chuan Xiao</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.05945v1-abstract-short" style="display: inline;">
        &hellip;collapse by mapping the generated images back to random noise. To save the effort of selecting the kernel function manually, we propose a soft selection method to automatically <span class="search-hit mathjax">learn</span> a characteristic kernel function. The experimental evaluation conducted on a set of synthetic and real image benchmarks (MNIST, CelebA, etc.) demonstrates that CKGAN generally o&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.05945v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05945v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.05945v1-abstract-full" style="display: none;">
        In this paper, we propose CKGAN, a novel generative adversarial network (GAN) variant based on an integral probability metrics framework with characteristic kernel (CKIPM). CKIPM, as a distance between two probability distributions, is designed to optimize the lowerbound of the maximum mean discrepancy (MMD) in a reproducing kernel Hilbert space, and thus can be used to train GANs. CKGAN mitigates the notorious problem of mode collapse by mapping the generated images back to random noise. To save the effort of selecting the kernel function manually, we propose a soft selection method to automatically <span class="search-hit mathjax">learn</span> a characteristic kernel function. The experimental evaluation conducted on a set of synthetic and real image benchmarks (MNIST, CelebA, etc.) demonstrates that CKGAN generally outperforms other MMD-based GANs. The results also show that at the cost of moderately more training time, the automatically selected kernel function delivers very close performance to the best of manually fine-tuned one on real image benchmarks and is able to improve the performances of other MMD-based GANs.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.05945v1-abstract-full').style.display = 'none'; document.getElementById('2504.05945v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Source codes are available at https://github.com/chuanxiao1983/CKGAN/</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.05928">arXiv:2504.05928</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.05928">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Evaluation of the impact of expert knowledge: How decision support scores impact the effectiveness of automatic knowledge-driven feature engineering (aKDFE)
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Bj%C3%B6rneld%2C+O">Olof Björneld</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hammar%2C+T">Tora Hammar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nilsson%2C+D">Daniel Nilsson</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lincke%2C+A">Alisa Lincke</a>, 
      
      <a href="/search/?searchtype=author&amp;query=L%C3%B6we%2C+W">Welf Löwe</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.05928v1-abstract-short" style="display: inline;">
        &hellip;patient-centric transformation applied by aKDFE proved to be a highly effective feature engineering approach. Limitations include a single-project focus, potential bias from <span class="search-hit mathjax">machine</span> <span class="search-hit mathjax">learning</span> pipeline methods, and reliance on AUROC. In conclusion, aKDFE, particularly with patient-centric transformation, improves ADE pre&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.05928v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05928v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.05928v1-abstract-full" style="display: none;">
        Adverse Drug Events (ADEs), harmful medication effects, pose significant healthcare challenges, impacting patient safety and costs. This study evaluates automatic Knowledge-Driven Feature Engineering (aKDFE) for improved ADE prediction from Electronic Health Record (EHR) data, comparing it with automated event-based Knowledge Discovery in Databases (KDD). We investigated how incorporating domain-specific ADE risk scores for prolonged heart QT interval, extracted from the Janusmed Riskprofile (Janusmed) Clinical Decision Support System (CDSS), affects prediction performance using EHR data and medication handling events. Results indicate that, while aKDFE step 1 (event-based feature generation) alone did not significantly improve ADE prediction performance, aKDFE step 2 (patient-centric transformation) enhances the prediction performance. High Area Under the Receiver Operating Characteristic curve (AUROC) values suggest strong feature correlations to the outcome, aligning with the predictive power of patients&#39; prior healthcare history for ADEs. Statistical analysis did not confirm that incorporating the Janusmed information (i) risk scores and (ii) medication route of administration into the model&#39;s feature set enhanced predictive performance. However, the patient-centric transformation applied by aKDFE proved to be a highly effective feature engineering approach. Limitations include a single-project focus, potential bias from <span class="search-hit mathjax">machine</span> <span class="search-hit mathjax">learning</span> pipeline methods, and reliance on AUROC. In conclusion, aKDFE, particularly with patient-centric transformation, improves ADE prediction from EHR data. Future work will explore attention-based models, event feature sequences, and automatic methods for incorporating domain knowledge into the aKDFE framework.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.05928v1-abstract-full').style.display = 'none'; document.getElementById('2504.05928v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">43 pages, including the Appendix, 19 tables and 13 figures</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          62R01; 68T05
        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.6
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.05923">arXiv:2504.05923</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.05923">pdf</a>, <a href="https://arxiv.org/format/2504.05923">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Uncovering Fairness through Data Complexity as an Early Indicator
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ferreira%2C+J+S">Juliett Suárez Ferreira</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Slavkovik%2C+M">Marija Slavkovik</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Casillas%2C+J">Jorge Casillas</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.05923v1-abstract-short" style="display: inline;">
        Fairness constitutes a concern within <span class="search-hit mathjax">machine</span> <span class="search-hit mathjax">learning</span> (ML) applications. Currently, there is no study on how disparities in classification complexity between privileged and unprivileged groups could influence the fairness of solutions, which serves as a preliminary indicator of potential unfairness. In this work, we i&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.05923v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05923v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.05923v1-abstract-full" style="display: none;">
        Fairness constitutes a concern within <span class="search-hit mathjax">machine</span> <span class="search-hit mathjax">learning</span> (ML) applications. Currently, there is no study on how disparities in classification complexity between privileged and unprivileged groups could influence the fairness of solutions, which serves as a preliminary indicator of potential unfairness. In this work, we investigate this gap, specifically, we focus on synthetic datasets designed to capture a variety of biases ranging from historical bias to measurement and representational bias to evaluate how various complexity metrics differences correlate with group fairness metrics. We then apply association rule mining to identify patterns that link disproportionate complexity differences between groups with fairness-related outcomes, offering data-centric indicators to guide bias mitigation. Our findings are also validated by their application in real-world problems, providing evidence that quantifying group-wise classification complexity can uncover early indicators of potential fairness challenges. This investigation helps practitioners to proactively address bias in classification tasks.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.05923v1-abstract-full').style.display = 'none'; document.getElementById('2504.05923v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.05918">arXiv:2504.05918</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.05918">pdf</a>, <a href="https://arxiv.org/format/2504.05918">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        
          
            <span class="tag is-small search-hit tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Deep RL-based Autonomous Navigation of Micro Aerial Vehicles (MAVs) in a complex GPS-denied Indoor Environment
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Singh%2C+A+K">Amit Kumar Singh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Duba%2C+P+K">Prasanth Kumar Duba</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rajalakshmi%2C+P">P. Rajalakshmi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.05918v1-abstract-short" style="display: inline;">
        &hellip;in these complex, GPS-denied scenarios because of their agility, low power consumption, and limited computational capabilities. In this paper, we propose a Reinforcement <span class="search-hit mathjax">Learning</span> based Deep-Proximal Policy Optimization (D-PPO) algorithm to enhance realtime navigation through improving the computation efficiency. The end-to-end network is trained in 3D realis&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.05918v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05918v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.05918v1-abstract-full" style="display: none;">
        The Autonomy of Unmanned Aerial Vehicles (UAVs) in indoor environments poses significant challenges due to the lack of reliable GPS signals in enclosed spaces such as warehouses, factories, and indoor facilities. Micro Aerial Vehicles (MAVs) are preferred for navigating in these complex, GPS-denied scenarios because of their agility, low power consumption, and limited computational capabilities. In this paper, we propose a Reinforcement <span class="search-hit mathjax">Learning</span> based Deep-Proximal Policy Optimization (D-PPO) algorithm to enhance realtime navigation through improving the computation efficiency. The end-to-end network is trained in 3D realistic meta-environments created using the Unreal Engine. With these trained meta-weights, the MAV system underwent extensive experimental trials in real-world indoor environments. The results indicate that the proposed method reduces computational latency by 91\% during training period without significant degradation in performance. The algorithm was tested on a DJI Tello drone, yielding similar results.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.05918v1-abstract-full').style.display = 'none'; document.getElementById('2504.05918v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
  </li>

</ol>


  <nav class="pagination is-small is-centered breathe-horizontal" role="navigation" aria-label="pagination">
    
    <a href=""
      class="pagination-previous is-invisible">Previous
    </a>
    
    
      <a href="/search/?query=machine+learning&amp;searchtype=all&amp;source=header&amp;start=50"
        class="pagination-next" >Next
      </a>
    
    <ul class="pagination-list">

      <li>
        <a href="/search/?query=machine+learning&amp;searchtype=all&amp;source=header&amp;start=0"
          class="pagination-link is-current"
          aria-label="Goto page 1">1
        </a>
      </li>

      
                                     
          
          <li>
            <a href="/search/?query=machine+learning&amp;searchtype=all&amp;source=header&amp;start=50"
              class="pagination-link "
              aria-label="Page 2"
              aria-current="page">2
            </a>
          </li>
          
          <li>
            <a href="/search/?query=machine+learning&amp;searchtype=all&amp;source=header&amp;start=100"
              class="pagination-link "
              aria-label="Page 3"
              aria-current="page">3
            </a>
          </li>
          
          <li>
            <a href="/search/?query=machine+learning&amp;searchtype=all&amp;source=header&amp;start=150"
              class="pagination-link "
              aria-label="Page 4"
              aria-current="page">4
            </a>
          </li>
          
          <li>
            <a href="/search/?query=machine+learning&amp;searchtype=all&amp;source=header&amp;start=200"
              class="pagination-link "
              aria-label="Page 5"
              aria-current="page">5
            </a>
          </li>
          
          <li><span class="pagination-ellipsis">&hellip;</span></li>
        
      
    </ul>
  </nav>
  

  


      <div class="is-hidden-tablet">
        <!-- feedback for mobile only -->
        <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
      </div>
    </div>

  </main>
  <footer>
    
    <div class="columns is-desktop" role="navigation" aria-label="Secondary">
  <!-- MetaColumn 1 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://info.arxiv.org/about">About</a></li>
          <li><a href="https://info.arxiv.org/help">Help</a></li>
        </ul>
      </div>
      <div class="column">
        <ul class="nav-spaced">
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
            <a href="https://info.arxiv.org/help/contact.html"> Contact</a>
          </li>
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
            <a href="https://info.arxiv.org/help/subscribe"> Subscribe</a>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 1 -->
  <!-- MetaColumn 2 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://info.arxiv.org/help/license/index.html">Copyright</a></li>
          <li><a href="https://info.arxiv.org/help/policies/privacy_policy.html">Privacy Policy</a></li>
        </ul>
      </div>
      <div class="column sorry-app-links">
        <ul class="nav-spaced">
          <li><a href="https://info.arxiv.org/help/web_accessibility.html">Web Accessibility Assistance</a></li>
          <li>
            <p class="help">
              <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
              Get status notifications via
              <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
              or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
            </p>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 2 -->
</div>
    
  </footer>
  <script src="https://static.arxiv.org/static/base/1.0.0a5/js/member_acknowledgement.js"></script>
  </body>
</html>